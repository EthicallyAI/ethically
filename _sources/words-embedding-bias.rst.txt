Words Embedding Bias
====================

Bolukbasi et al. Debiasing
--------------------------

Auditing and adjusting the gender bias in words embedding.
refer to the article for concepts, methods and details:
Bolukbasi Tolga, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, and Adam T. Kalai. `Man is to computer programmer as woman is to homemaker? debiasing word embeddings <https://arxiv.org/abs/1607.06520>`_. NIPS 2016.

Usage
^^^^^
.. code:: python

   >>> from ethically.we import GenderBiasWE
   >>> from gensim import downloader
   >>> w2v_model = downloader.load('word2vec-google-news-300')
   >>> w2v_gender_bias_we = GenderBiasWE(w2v_model)
   >>> w2v_gender_bias_we.calc_direct_bias()
   0.07307904249481942
   >>> w2v_gender_bias_we.debias()
   >>> w2v_gender_bias_we.calc_direct_bias()
   1.7964246601064155e-09

Full reference: :class:`~ethically.we.bias.GenderBiasWE`


Types of Bias
~~~~~~~~~~~~~

Direct Bias
"""""""""""

1. Associations
   Words that are closer to one end (e.g., *he*) than to the other end (*she*).
   For example, occupational stereotypes (page 7).
   Calculated by :meth:`~ethically.we.bias.BiasWordsEmbedding.calc_direct_bias`.

2. Analogies
    Analogies of *he:x::she:y*.
    For example analogies exhibiting stereotypes (page 7).
    Generated by :meth:`~ethically.we.bias.BiasWordsEmbedding.generate_analogies`.


Indirect Bias
"""""""""""""

Projection of a neutral words into a two neutral words direction
is explained in a great portion by a shared bias direction projection.

Calculated by :meth:`~ethically.we.bias.BiasWordsEmbedding.calc_indirect_bias`
and :meth:`~ethically.we.bias.GenderBiasWE.generate_closest_words_indirect_bias`.


Credits
^^^^^^^
Data and part of the code from:
https://github.com/tolga-b/debiaswe
(MIT License)
