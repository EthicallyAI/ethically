
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Word Embedding Bias &#8212; Responsibly 0.1.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Demos" href="demos.html" />
    <link rel="prev" title="Classification Fairness" href="fairness.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-responsibly.we">
<span id="word-embedding-bias"></span><h1>Word Embedding Bias<a class="headerlink" href="#module-responsibly.we" title="Permalink to this headline">¶</a></h1>
<p>Metrics and debiasing for bias (such as gender and race) in word embedding.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The following paper suggests that the current methods
have an only superficial effect on the bias in word embeddings:</p>
<p>Gonen, H., &amp; Goldberg, Y. (2019).
<a class="reference external" href="https://arxiv.org/abs/1903.03862">Lipstick on a Pig:
Debiasing Methods Cover up Systematic Gender Biases
in Word Embeddings But do not Remove Them</a>.
arXiv preprint arXiv:1903.03862.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The following paper criticize using
<a class="reference internal" href="#responsibly.we.utils.most_similar" title="responsibly.we.utils.most_similar"><code class="xref py py-func docutils literal notranslate"><span class="pre">most_similar()</span></code></a>
function from <a class="reference external" href="https://radimrehurek.com/gensim/">gensim</a> in the context
of word embedding bias and the generating analogies process:</p>
<p>Nissim, M., van Noord, R., van der Goot, R. (2019).
<a class="reference external" href="https://arxiv.org/abs/1905.09866">Fair is Better than Sensational: Man is to Doctor
as Woman is to Doctor</a>.</p>
<p>Therefore, in <em>responsibly</em> there is an implementation of
<a class="reference internal" href="#responsibly.we.utils.most_similar" title="responsibly.we.utils.most_similar"><code class="xref py py-func docutils literal notranslate"><span class="pre">most_similar()</span></code></a> with the argument
<cite>unrestricted</cite> that doesn’t filter the results.
Similar argument exist for
<a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding.generate_analogies" title="responsibly.we.bias.BiasWordEmbedding.generate_analogies"><code class="xref py py-meth docutils literal notranslate"><span class="pre">generate_analogies()</span></code></a>.</p>
</div>
<p>Currently, three methods are supported:</p>
<ol class="arabic simple">
<li><p>Bolukbasi et al. (2016) bias measure and debiasing
- <a class="reference internal" href="#module-responsibly.we.bias" title="responsibly.we.bias"><code class="xref py py-mod docutils literal notranslate"><span class="pre">responsibly.we.bias</span></code></a></p></li>
<li><p>WEAT measure
- <a class="reference internal" href="#module-responsibly.we.weat" title="responsibly.we.weat"><code class="xref py py-mod docutils literal notranslate"><span class="pre">responsibly.we.weat</span></code></a></p></li>
<li><p>Gonen et al. (2019) clustering as classification
of biased neutral words
- <a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding.plot_most_biased_clustering" title="responsibly.we.bias.BiasWordEmbedding.plot_most_biased_clustering"><code class="xref py py-meth docutils literal notranslate"><span class="pre">responsibly.we.bias.BiasWordEmbedding.plot_most_biased_clustering()</span></code></a></p></li>
</ol>
<p>Besides, some of the standard benchmarks for
word embeddings are also available, primarily to check
the impact of debiasing performance.</p>
<p>Refer to the <a class="reference external" href="notebooks/demo-word-embedding-bias.html">Word Embedding demo</a>
for a complete usage example.</p>
<p>For a technical discussion about the various bias metrics,
refer to the page <a class="reference internal" href="word-embedding-bias-metric-analysis.html"><span class="doc">Analysis of Word Embedding Bias Metrics</span></a>.</p>
<div class="section" id="module-responsibly.we.bias">
<span id="bolukbasi-bias-measure-and-debiasing"></span><h2>Bolukbasi Bias Measure and Debiasing<a class="headerlink" href="#module-responsibly.we.bias" title="Permalink to this headline">¶</a></h2>
<p>Measuring and adjusting bias in word embedding by Bolukbasi (2016).</p>
<dl class="simple">
<dt>References:</dt><dd><ul class="simple">
<li><p>Bolukbasi, T., Chang, K. W., Zou, J. Y., Saligrama, V.,
&amp; Kalai, A. T. (2016).
<a class="reference external" href="https://arxiv.org/abs/1607.06520">Man is to computer programmer as woman is to homemaker?
debiasing word embeddings</a>.
In Advances in neural information processing systems
(pp. 4349-4357).</p></li>
<li><p>The code and data is based on the GitHub repository:
<a class="reference external" href="https://github.com/tolga-b/debiaswe">https://github.com/tolga-b/debiaswe</a> (MIT License).</p></li>
<li><p>Gonen, H., &amp; Goldberg, Y. (2019).
<a class="reference external" href="https://arxiv.org/abs/1903.03862">Lipstick on a Pig:
Debiasing Methods Cover up Systematic Gender Biases
in Word Embeddings But do not Remove Them</a>.
arXiv preprint arXiv:1903.03862.</p></li>
<li><p>Nissim, M., van Noord, R., van der Goot, R. (2019).
<a class="reference external" href="https://arxiv.org/abs/1905.09866">Fair is Better than Sensational: Man is to Doctor
as Woman is to Doctor</a>.</p></li>
</ul>
</dd>
</dl>
<div class="section" id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">responsibly.we</span> <span class="kn">import</span> <span class="n">GenderBiasWE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">downloader</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w2v_model</span> <span class="o">=</span> <span class="n">downloader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;word2vec-google-news-300&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w2v_gender_bias_we</span> <span class="o">=</span> <span class="n">GenderBiasWE</span><span class="p">(</span><span class="n">w2v_model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w2v_gender_bias_we</span><span class="o">.</span><span class="n">calc_direct_bias</span><span class="p">()</span>
<span class="go">0.07307904249481942</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w2v_gender_bias_we</span><span class="o">.</span><span class="n">debias</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w2v_gender_bias_we</span><span class="o">.</span><span class="n">calc_direct_bias</span><span class="p">()</span>
<span class="go">1.7964246601064155e-09</span>
</pre></div>
</div>
</div>
<div class="section" id="types-of-bias">
<h3>Types of Bias<a class="headerlink" href="#types-of-bias" title="Permalink to this headline">¶</a></h3>
<div class="section" id="direct-bias">
<h4>Direct Bias<a class="headerlink" href="#direct-bias" title="Permalink to this headline">¶</a></h4>
<ol class="arabic simple">
<li><dl class="simple">
<dt>Associations</dt><dd><p>Words that are closer to one end (e.g., <em>he</em>) than to
the other end (<em>she</em>).
For example, occupational stereotypes (page 7).
Calculated by
<a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding.calc_direct_bias" title="responsibly.we.bias.BiasWordEmbedding.calc_direct_bias"><code class="xref py py-meth docutils literal notranslate"><span class="pre">calc_direct_bias()</span></code></a>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Analogies</dt><dd><p>Analogies of <em>he:x::she:y</em>.
For example analogies exhibiting stereotypes (page 7).
Generated by
<a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding.generate_analogies" title="responsibly.we.bias.BiasWordEmbedding.generate_analogies"><code class="xref py py-meth docutils literal notranslate"><span class="pre">generate_analogies()</span></code></a>.</p>
</dd>
</dl>
</li>
</ol>
</div>
<div class="section" id="indirect-bias">
<h4>Indirect Bias<a class="headerlink" href="#indirect-bias" title="Permalink to this headline">¶</a></h4>
<p>Projection of a neutral words into a two neutral words direction
is explained in a great portion by a shared bias direction projection.</p>
<p>Calculated by
<a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding.calc_indirect_bias" title="responsibly.we.bias.BiasWordEmbedding.calc_indirect_bias"><code class="xref py py-meth docutils literal notranslate"><span class="pre">calc_indirect_bias()</span></code></a>
and
<a class="reference internal" href="#responsibly.we.bias.GenderBiasWE.generate_closest_words_indirect_bias" title="responsibly.we.bias.GenderBiasWE.generate_closest_words_indirect_bias"><code class="xref py py-meth docutils literal notranslate"><span class="pre">generate_closest_words_indirect_bias()</span></code></a>.</p>
<dl class="class">
<dt id="responsibly.we.bias.BiasWordEmbedding">
<em class="property">class </em><code class="sig-prename descclassname">responsibly.we.bias.</code><code class="sig-name descname">BiasWordEmbedding</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">only_lower=False</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">identify_direction=False</em>, <em class="sig-param">to_normalize=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Measure and adjust a bias in English word embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding model of <code class="docutils literal notranslate"><span class="pre">gensim.model.KeyedVectors</span></code></p></li>
<li><p><strong>only_lower</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether the word embedding contrains
only lower case words</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Set verbosity</p></li>
<li><p><strong>to_normalize</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to normalize all the vectors
(recommended!)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.project_on_direction">
<code class="sig-name descname">project_on_direction</code><span class="sig-paren">(</span><em class="sig-param">word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.project_on_direction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.project_on_direction" title="Permalink to this definition">¶</a></dt>
<dd><p>Project the normalized vector of the word on the direction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>word</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – The word tor project</p>
</dd>
<dt class="field-even">Return float</dt>
<dd class="field-even"><p>The projection scalar</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.calc_projection_data">
<code class="sig-name descname">calc_projection_data</code><span class="sig-paren">(</span><em class="sig-param">words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.calc_projection_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.calc_projection_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate projection, projected and rejected vectors of a words list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of words</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.25.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a> of the projection,
projected and rejected vectors of the words list</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.plot_projection_scores">
<code class="sig-name descname">plot_projection_scores</code><span class="sig-paren">(</span><em class="sig-param">words</em>, <em class="sig-param">n_extreme=10</em>, <em class="sig-param">ax=None</em>, <em class="sig-param">axis_projection_step=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.plot_projection_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.plot_projection_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the projection scalar of words on the direction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – The words tor project</p></li>
<li><p><strong>or None n_extreme</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number of extreme words to show</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The ax object of the plot</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.plot_dist_projections_on_direction">
<code class="sig-name descname">plot_dist_projections_on_direction</code><span class="sig-paren">(</span><em class="sig-param">word_groups</em>, <em class="sig-param">ax=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.plot_dist_projections_on_direction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.plot_dist_projections_on_direction" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the projection scalars distribution on the direction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>word_groups word</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – The groups to projects</p>
</dd>
<dt class="field-even">Return float</dt>
<dd class="field-even"><p>The ax object of the plot</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.plot_bias_across_word_embeddings">
<em class="property">classmethod </em><code class="sig-name descname">plot_bias_across_word_embeddings</code><span class="sig-paren">(</span><em class="sig-param">word_embedding_bias_dict</em>, <em class="sig-param">words</em>, <em class="sig-param">ax=None</em>, <em class="sig-param">scatter_kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.plot_bias_across_word_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.plot_bias_across_word_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the projections of same words of two word mbeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>word_embedding_bias_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – <code class="docutils literal notranslate"><span class="pre">WordsEmbeddingBias</span></code> objects
as values,
and their names as keys.</p></li>
<li><p><strong>words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – Words to be projected.</p></li>
<li><p><strong>scatter_kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – Kwargs for matplotlib.pylab.scatter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The ax object of the plot</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.generate_analogies">
<code class="sig-name descname">generate_analogies</code><span class="sig-paren">(</span><em class="sig-param">n_analogies=100</em>, <em class="sig-param">seed='ends'</em>, <em class="sig-param">multiple=False</em>, <em class="sig-param">delta=1.0</em>, <em class="sig-param">restrict_vocab=30000</em>, <em class="sig-param">unrestricted=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.generate_analogies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.generate_analogies" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate analogies based on a seed vector.</p>
<p>x - y ~ seed vector.
or a:x::b:y when a-b ~ seed vector.</p>
<p>The seed vector can be defined by two word ends,
or by the bias direction.</p>
<p><code class="docutils literal notranslate"><span class="pre">delta</span></code> is used for semantically coherent. Default vale of 1
corresponds to an angle &lt;= pi/3.</p>
<p>There is criticism regarding generating analogies
when used with <cite>unstricted=False</cite> and not ignoring analogies
with <cite>match</cite> column equal to <cite>False</cite>.
Tolga’s technique of generating analogies, as implemented in this
method, is limited inherently to analogies with x != y, which may
be force “fake” bias analogies.</p>
<p>See:</p>
<ul class="simple">
<li><p>Nissim, M., van Noord, R., van der Goot, R. (2019).
<a class="reference external" href="https://arxiv.org/abs/1905.09866">Fair is Better than Sensational: Man is to Doctor
as Woman is to Doctor</a>.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> – The definition of the seed vector.
Either by a tuple of two word ends,
or by <cite>‘ends</cite> for the pre-defined ends
or by <cite>‘direction’</cite> for the pre-defined direction vector.</p></li>
<li><p><strong>n_analogies</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of analogies to generate.</p></li>
<li><p><strong>multiple</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to allow multiple appearances of a word
in the analogies.</p></li>
<li><p><strong>delta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Threshold for semantic similarity.
The maximal distance between x and y.</p></li>
<li><p><strong>restrict_vocab</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The vocabulary size to use.</p></li>
<li><p><strong>unrestricted</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to validate the generated analogies
with unrestricted <cite>most_similar</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Data Frame of analogies (x, y), their distances,
and their cosine similarity scores</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.calc_direct_bias">
<code class="sig-name descname">calc_direct_bias</code><span class="sig-paren">(</span><em class="sig-param">neutral_words</em>, <em class="sig-param">c=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.calc_direct_bias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.calc_direct_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the direct bias.</p>
<p>Based on the projection of neutral words on the direction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neutral_words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of neutral words</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – Strictness of bias measuring</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The direct bias</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.calc_indirect_bias">
<code class="sig-name descname">calc_indirect_bias</code><span class="sig-paren">(</span><em class="sig-param">word1</em>, <em class="sig-param">word2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.calc_indirect_bias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.calc_indirect_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the indirect bias between two words.</p>
<p>Based on the amount of shared projection of the words on the direction.</p>
<p>Also called PairBias.
:param str word1: First word
:param str word2: Second word
:type c: float or None
:return The indirect bias between the two words</p>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.generate_closest_words_indirect_bias">
<code class="sig-name descname">generate_closest_words_indirect_bias</code><span class="sig-paren">(</span><em class="sig-param">neutral_positive_end</em>, <em class="sig-param">neutral_negative_end</em>, <em class="sig-param">words=None</em>, <em class="sig-param">n_extreme=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.generate_closest_words_indirect_bias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.generate_closest_words_indirect_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate closest words to a neutral direction and their indirect bias.</p>
<p>The direction of the neutral words is used to find
the most extreme words.
The indirect bias is calculated between the most extreme words
and the closest end.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neutral_positive_end</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – A word that define the positive side
of the neutral direction.</p></li>
<li><p><strong>neutral_negative_end</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – A word that define the negative side
of the neutral direction.</p></li>
<li><p><strong>words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of words to project on the neutral direction.</p></li>
<li><p><strong>n_extreme</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number for the most extreme words
(positive and negative) to show.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Data Frame of the most extreme words
with their projection scores and indirect biases.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.debias">
<code class="sig-name descname">debias</code><span class="sig-paren">(</span><em class="sig-param">method='hard'</em>, <em class="sig-param">neutral_words=None</em>, <em class="sig-param">equality_sets=None</em>, <em class="sig-param">inplace=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.debias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.debias" title="Permalink to this definition">¶</a></dt>
<dd><p>Debias the word embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – The method of debiasing.</p></li>
<li><p><strong>neutral_words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of neutral words
for the neutralize step</p></li>
<li><p><strong>equality_sets</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of equality sets,
for the equalize step.
The sets represent the direction.</p></li>
<li><p><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to debias the object inplace
or return a new one</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>After calling <cite>debias</cite>,
all the vectors of the word embedding
will be normalized to unit length.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.evaluate_word_embedding">
<code class="sig-name descname">evaluate_word_embedding</code><span class="sig-paren">(</span><em class="sig-param">kwargs_word_pairs=None</em>, <em class="sig-param">kwargs_word_analogies=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.evaluate_word_embedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.evaluate_word_embedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate word pairs tasks and word analogies tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding.</p></li>
<li><p><strong>kwargs_word_pairs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – Kwargs for
evaluate_word_pairs
method.</p></li>
<li><p><strong>kwargs_word_analogies</strong> – Kwargs for
evaluate_word_analogies
method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.25.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a>
for the evaluation results.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.learn_full_specific_words">
<code class="sig-name descname">learn_full_specific_words</code><span class="sig-paren">(</span><em class="sig-param">seed_specific_words</em>, <em class="sig-param">max_non_specific_examples=None</em>, <em class="sig-param">debug=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.learn_full_specific_words"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.learn_full_specific_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn specific words given a list of seed specific wordsself.</p>
<p>Using Linear SVM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed_specific_words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of seed specific words</p></li>
<li><p><strong>max_non_specific_examples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number of non-specific words
to sample for training</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of learned specific words and the classifier object</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.compute_factual_association">
<code class="sig-name descname">compute_factual_association</code><span class="sig-paren">(</span><em class="sig-param">factual_properity</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.compute_factual_association"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.compute_factual_association" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute association of a factual property to the projection.</p>
<p>Inspired by WEFAT (Word-Embedding Factual Association Test),
but it is not the same:
- Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017).
<a class="reference external" href="http://opus.bath.ac.uk/55288/">Semantics derived automatically
from language corpora contain human-like biases</a>.
Science, 356(6334), 183-186.</p>
<p>In a future version, the WEFAT will also be implemented.</p>
<p>If a word doesn’t exist in the word embedding,
then it will be filtered out.</p>
<p>For example, in <a class="reference internal" href="#responsibly.we.bias.GenderBiasWE" title="responsibly.we.bias.GenderBiasWE"><code class="xref py py-class docutils literal notranslate"><span class="pre">responsibly.we.bias.GenderBiasWE</span></code></a>,
the defuat factual property is the percentage of female
in various occupations
from the Labor Force Statistics of 2017 Population Survey,
Taken from: <a class="reference external" href="https://arxiv.org/abs/1804.06876">https://arxiv.org/abs/1804.06876</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>factual_properity</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – Dictionary of words
and their factual values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Pearson r, pvalue and the words with their
associated factual values
and their projection on the bias direction.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.plot_factual_association">
<code class="sig-name descname">plot_factual_association</code><span class="sig-paren">(</span><em class="sig-param">factual_properity</em>, <em class="sig-param">ax=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.plot_factual_association"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.plot_factual_association" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot association of a factual property to the projection.</p>
<p>See: <a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding.compute_factual_association" title="responsibly.we.bias.BiasWordEmbedding.compute_factual_association"><code class="xref py py-meth docutils literal notranslate"><span class="pre">BiasWordEmbedding.compute_factual_association()</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>factual_properity</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – Dictionary of words
and their factual values.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.BiasWordEmbedding.plot_most_biased_clustering">
<em class="property">static </em><code class="sig-name descname">plot_most_biased_clustering</code><span class="sig-paren">(</span><em class="sig-param">biased</em>, <em class="sig-param">debiased</em>, <em class="sig-param">seed='ends'</em>, <em class="sig-param">n_extreme=500</em>, <em class="sig-param">random_state=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#BiasWordEmbedding.plot_most_biased_clustering"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.BiasWordEmbedding.plot_most_biased_clustering" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot clustering as classification of biased neutral words.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>biased</strong> – Biased word embedding of
<a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding" title="responsibly.we.bias.BiasWordEmbedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">BiasWordEmbedding</span></code></a>.</p></li>
<li><p><strong>debiased</strong> – Debiased word embedding of
<a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding" title="responsibly.we.bias.BiasWordEmbedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">BiasWordEmbedding</span></code></a>.</p></li>
<li><p><strong>seed</strong> – The definition of the seed vector.
Either by a tuple of two word ends,
or by <cite>‘ends</cite> for the pre-defined ends
or by <cite>‘direction’</cite> for
the pre-defined direction vector.</p></li>
<li><p><strong>n_extrem</strong> – The number of extreme biased
neutral words to use.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of list of ax objects of the plot,
and a dictionary with the most positive
and negative words.</p>
</dd>
</dl>
<p>Based on:</p>
<ul class="simple">
<li><p>Gonen, H., &amp; Goldberg, Y. (2019).
<a class="reference external" href="https://arxiv.org/abs/1903.03862">Lipstick on a Pig:
Debiasing Methods Cover up Systematic Gender Biases
in Word Embeddings But do not Remove
Them</a>.
arXiv preprint arXiv:1903.03862.</p></li>
<li><p><a class="reference external" href="https://github.com/gonenhila/gender_bias_lipstick">https://github.com/gonenhila/gender_bias_lipstick</a></p></li>
</ul>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="responsibly.we.bias.GenderBiasWE">
<em class="property">class </em><code class="sig-prename descclassname">responsibly.we.bias.</code><code class="sig-name descname">GenderBiasWE</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">only_lower=False</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">identify_direction='pca'</em>, <em class="sig-param">to_normalize=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding" title="responsibly.we.bias.BiasWordEmbedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">responsibly.we.bias.BiasWordEmbedding</span></code></a></p>
<p>Measure and adjust the Gender Bias in English Word Embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding model of <code class="docutils literal notranslate"><span class="pre">gensim.model.KeyedVectors</span></code></p></li>
<li><p><strong>only_lower</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether the word embedding contrains
only lower case words</p></li>
<li><p><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Set verbosity</p></li>
<li><p><strong>identify_direction</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – Set the method of identifying
the gender direction:
<cite>‘single’</cite>, <cite>‘sum’</cite> or <cite>‘pca’</cite>.</p></li>
<li><p><strong>to_normalize</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to normalize all the vectors
(recommended!)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.plot_projection_scores">
<code class="sig-name descname">plot_projection_scores</code><span class="sig-paren">(</span><em class="sig-param">words='professions'</em>, <em class="sig-param">n_extreme=10</em>, <em class="sig-param">ax=None</em>, <em class="sig-param">axis_projection_step=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.plot_projection_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.plot_projection_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the projection scalar of words on the direction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – The words tor project</p></li>
<li><p><strong>or None n_extreme</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number of extreme words to show</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The ax object of the plot</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.plot_dist_projections_on_direction">
<code class="sig-name descname">plot_dist_projections_on_direction</code><span class="sig-paren">(</span><em class="sig-param">word_groups='bolukbasi'</em>, <em class="sig-param">ax=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.plot_dist_projections_on_direction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.plot_dist_projections_on_direction" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the projection scalars distribution on the direction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>word_groups word</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – The groups to projects</p>
</dd>
<dt class="field-even">Return float</dt>
<dd class="field-even"><p>The ax object of the plot</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.plot_bias_across_word_embeddings">
<em class="property">classmethod </em><code class="sig-name descname">plot_bias_across_word_embeddings</code><span class="sig-paren">(</span><em class="sig-param">word_embedding_bias_dict</em>, <em class="sig-param">ax=None</em>, <em class="sig-param">scatter_kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.plot_bias_across_word_embeddings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.plot_bias_across_word_embeddings" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the projections of same words of two word mbeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>word_embedding_bias_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – <code class="docutils literal notranslate"><span class="pre">WordsEmbeddingBias</span></code> objects
as values,
and their names as keys.</p></li>
<li><p><strong>words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – Words to be projected.</p></li>
<li><p><strong>scatter_kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – Kwargs for matplotlib.pylab.scatter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The ax object of the plot</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.calc_direct_bias">
<code class="sig-name descname">calc_direct_bias</code><span class="sig-paren">(</span><em class="sig-param">neutral_words='professions'</em>, <em class="sig-param">c=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.calc_direct_bias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.calc_direct_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the direct bias.</p>
<p>Based on the projection of neutral words on the direction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neutral_words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of neutral words</p></li>
<li><p><strong>c</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – Strictness of bias measuring</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The direct bias</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.generate_closest_words_indirect_bias">
<code class="sig-name descname">generate_closest_words_indirect_bias</code><span class="sig-paren">(</span><em class="sig-param">neutral_positive_end</em>, <em class="sig-param">neutral_negative_end</em>, <em class="sig-param">words='professions'</em>, <em class="sig-param">n_extreme=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.generate_closest_words_indirect_bias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.generate_closest_words_indirect_bias" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate closest words to a neutral direction and their indirect bias.</p>
<p>The direction of the neutral words is used to find
the most extreme words.
The indirect bias is calculated between the most extreme words
and the closest end.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neutral_positive_end</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – A word that define the positive side
of the neutral direction.</p></li>
<li><p><strong>neutral_negative_end</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – A word that define the negative side
of the neutral direction.</p></li>
<li><p><strong>words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of words to project on the neutral direction.</p></li>
<li><p><strong>n_extreme</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number for the most extreme words
(positive and negative) to show.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Data Frame of the most extreme words
with their projection scores and indirect biases.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.debias">
<code class="sig-name descname">debias</code><span class="sig-paren">(</span><em class="sig-param">method='hard'</em>, <em class="sig-param">neutral_words=None</em>, <em class="sig-param">equality_sets=None</em>, <em class="sig-param">inplace=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.debias"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.debias" title="Permalink to this definition">¶</a></dt>
<dd><p>Debias the word embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – The method of debiasing.</p></li>
<li><p><strong>neutral_words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of neutral words
for the neutralize step</p></li>
<li><p><strong>equality_sets</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of equality sets,
for the equalize step.
The sets represent the direction.</p></li>
<li><p><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to debias the object inplace
or return a new one</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>After calling <cite>debias</cite>,
all the vectors of the word embedding
will be normalized to unit length.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.learn_full_specific_words">
<code class="sig-name descname">learn_full_specific_words</code><span class="sig-paren">(</span><em class="sig-param">seed_specific_words='bolukbasi'</em>, <em class="sig-param">max_non_specific_examples=None</em>, <em class="sig-param">debug=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.learn_full_specific_words"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.learn_full_specific_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn specific words given a list of seed specific wordsself.</p>
<p>Using Linear SVM.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed_specific_words</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of seed specific words</p></li>
<li><p><strong>max_non_specific_examples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number of non-specific words
to sample for training</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>List of learned specific words and the classifier object</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.compute_factual_association">
<code class="sig-name descname">compute_factual_association</code><span class="sig-paren">(</span><em class="sig-param">factual_properity={'accountant': 61</em>, <em class="sig-param">'analyst': 41</em>, <em class="sig-param">'assistant': 85</em>, <em class="sig-param">'attendant': 76</em>, <em class="sig-param">'auditor': 61</em>, <em class="sig-param">'baker': 65</em>, <em class="sig-param">'carpenter': 2</em>, <em class="sig-param">'cashier': 73</em>, <em class="sig-param">'ceo': 39</em>, <em class="sig-param">'chief': 27</em>, <em class="sig-param">'cleaner': 89</em>, <em class="sig-param">'clerk': 72</em>, <em class="sig-param">'construction_worker': 4</em>, <em class="sig-param">'cook': 38</em>, <em class="sig-param">'counselors': 73</em>, <em class="sig-param">'designers': 54</em>, <em class="sig-param">'developer': 20</em>, <em class="sig-param">'driver': 6</em>, <em class="sig-param">'editor': 52</em>, <em class="sig-param">'farmer': 22</em>, <em class="sig-param">'guard': 22</em>, <em class="sig-param">'hairdressers': 92</em>, <em class="sig-param">'housekeeper': 89</em>, <em class="sig-param">'janitor': 34</em>, <em class="sig-param">'laborer': 4</em>, <em class="sig-param">'lawyer': 35</em>, <em class="sig-param">'librarian': 84</em>, <em class="sig-param">'manager': 43</em>, <em class="sig-param">'mechanician': 4</em>, <em class="sig-param">'mover': 18</em>, <em class="sig-param">'nurse': 90</em>, <em class="sig-param">'physician': 38</em>, <em class="sig-param">'receptionist': 90</em>, <em class="sig-param">'salesperson': 48</em>, <em class="sig-param">'secretary': 95</em>, <em class="sig-param">'sewer': 80</em>, <em class="sig-param">'sheriff': 14</em>, <em class="sig-param">'supervisor': 44</em>, <em class="sig-param">'teacher': 78</em>, <em class="sig-param">'writer': 63}</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.compute_factual_association"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.compute_factual_association" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute association of a factual property to the projection.</p>
<p>Inspired by WEFAT (Word-Embedding Factual Association Test),
but it is not the same:
- Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017).
<a class="reference external" href="http://opus.bath.ac.uk/55288/">Semantics derived automatically
from language corpora contain human-like biases</a>.
Science, 356(6334), 183-186.</p>
<p>In a future version, the WEFAT will also be implemented.</p>
<p>If a word doesn’t exist in the word embedding,
then it will be filtered out.</p>
<p>For example, in <a class="reference internal" href="#responsibly.we.bias.GenderBiasWE" title="responsibly.we.bias.GenderBiasWE"><code class="xref py py-class docutils literal notranslate"><span class="pre">responsibly.we.bias.GenderBiasWE</span></code></a>,
the defuat factual property is the percentage of female
in various occupations
from the Labor Force Statistics of 2017 Population Survey,
Taken from: <a class="reference external" href="https://arxiv.org/abs/1804.06876">https://arxiv.org/abs/1804.06876</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>factual_properity</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – Dictionary of words
and their factual values.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Pearson r, pvalue and the words with their
associated factual values
and their projection on the bias direction.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="responsibly.we.bias.GenderBiasWE.plot_factual_association">
<code class="sig-name descname">plot_factual_association</code><span class="sig-paren">(</span><em class="sig-param">factual_properity={'accountant': 61</em>, <em class="sig-param">'analyst': 41</em>, <em class="sig-param">'assistant': 85</em>, <em class="sig-param">'attendant': 76</em>, <em class="sig-param">'auditor': 61</em>, <em class="sig-param">'baker': 65</em>, <em class="sig-param">'carpenter': 2</em>, <em class="sig-param">'cashier': 73</em>, <em class="sig-param">'ceo': 39</em>, <em class="sig-param">'chief': 27</em>, <em class="sig-param">'cleaner': 89</em>, <em class="sig-param">'clerk': 72</em>, <em class="sig-param">'construction_worker': 4</em>, <em class="sig-param">'cook': 38</em>, <em class="sig-param">'counselors': 73</em>, <em class="sig-param">'designers': 54</em>, <em class="sig-param">'developer': 20</em>, <em class="sig-param">'driver': 6</em>, <em class="sig-param">'editor': 52</em>, <em class="sig-param">'farmer': 22</em>, <em class="sig-param">'guard': 22</em>, <em class="sig-param">'hairdressers': 92</em>, <em class="sig-param">'housekeeper': 89</em>, <em class="sig-param">'janitor': 34</em>, <em class="sig-param">'laborer': 4</em>, <em class="sig-param">'lawyer': 35</em>, <em class="sig-param">'librarian': 84</em>, <em class="sig-param">'manager': 43</em>, <em class="sig-param">'mechanician': 4</em>, <em class="sig-param">'mover': 18</em>, <em class="sig-param">'nurse': 90</em>, <em class="sig-param">'physician': 38</em>, <em class="sig-param">'receptionist': 90</em>, <em class="sig-param">'salesperson': 48</em>, <em class="sig-param">'secretary': 95</em>, <em class="sig-param">'sewer': 80</em>, <em class="sig-param">'sheriff': 14</em>, <em class="sig-param">'supervisor': 44</em>, <em class="sig-param">'teacher': 78</em>, <em class="sig-param">'writer': 63}</em>, <em class="sig-param">ax=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/bias.html#GenderBiasWE.plot_factual_association"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.bias.GenderBiasWE.plot_factual_association" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot association of a factual property to the projection.</p>
<p>See: <a class="reference internal" href="#responsibly.we.bias.BiasWordEmbedding.compute_factual_association" title="responsibly.we.bias.BiasWordEmbedding.compute_factual_association"><code class="xref py py-meth docutils literal notranslate"><span class="pre">BiasWordEmbedding.compute_factual_association()</span></code></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>factual_properity</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – Dictionary of words
and their factual values.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
</div>
<div class="section" id="module-responsibly.we.weat">
<span id="weat"></span><h2>WEAT<a class="headerlink" href="#module-responsibly.we.weat" title="Permalink to this headline">¶</a></h2>
<p>Compute WEAT score of a Word Embedding.</p>
<p>WEAT is a bias measurement method for word embedding,
which is inspired by the <a class="reference external" href="https://en.wikipedia.org/wiki/Implicit-association_test">IAT</a>
(Implicit Association Test) for humans.
It measures the similarity between two sets of <em>target words</em>
(e.g., programmer, engineer, scientist, … and nurse, teacher, librarian, …)
and two sets of <em>attribute words</em> (e.g., man, male, … and woman, female …).
A p-value is calculated using a permutation-test.</p>
<dl class="simple">
<dt>Reference:</dt><dd><ul class="simple">
<li><p>Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017).
<a class="reference external" href="http://opus.bath.ac.uk/55288/">Semantics derived automatically
from language corpora contain human-like biases</a>.
Science, 356(6334), 183-186.</p></li>
</ul>
</dd>
</dl>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The effect size and pvalue in the WEAT have
entirely different meaning from those reported in IATs (original finding).
Refer to the paper for more details.</p>
</div>
<p>Stimulus and original finding from:</p>
<ul class="simple">
<li><p>[0, 1, 2]
A. G. Greenwald, D. E. McGhee, J. L. Schwartz,
Measuring individual differences in implicit cognition:
the implicit association test.,
Journal of personality and social psychology 74, 1464 (1998).</p></li>
<li><p>[3, 4]:
M. Bertrand, S. Mullainathan, Are Emily and Greg more employable
than Lakisha and Jamal? a field experiment on labor market discrimination,
The American Economic Review 94, 991 (2004).</p></li>
<li><p>[5, 6, 9]:
B. A. Nosek, M. Banaji, A. G. Greenwald, Harvesting implicit group attitudes
and beliefs from a demonstration web site.,
Group Dynamics: Theory, Research, and Practice 6, 101 (2002).</p></li>
<li><p>[7]:
B. A. Nosek, M. R. Banaji, A. G. Greenwald, Math=male, me=female,
therefore math≠me.,
Journal of Personality and Social Psychology 83, 44 (2002).</p></li>
<li><p>[8]
P. D. Turney, P. Pantel, From frequency to meaning:
Vector space models of semantics,
Journal of Artificial Intelligence Research 37, 141 (2010).</p></li>
</ul>
<dl class="function">
<dt id="responsibly.we.weat.calc_single_weat">
<code class="sig-prename descclassname">responsibly.we.weat.</code><code class="sig-name descname">calc_single_weat</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">first_target</em>, <em class="sig-param">second_target</em>, <em class="sig-param">first_attribute</em>, <em class="sig-param">second_attribute</em>, <em class="sig-param">with_pvalue=True</em>, <em class="sig-param">pvalue_kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/weat.html#calc_single_weat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.weat.calc_single_weat" title="Permalink to this definition">¶</a></dt>
<dd><p>Calc the WEAT result of a word embedding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding model of <code class="docutils literal notranslate"><span class="pre">gensim.model.KeyedVectors</span></code></p></li>
<li><p><strong>first_target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – First target words list and its name</p></li>
<li><p><strong>second_target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – Second target words list and its name</p></li>
<li><p><strong>first_attribute</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – First attribute words list and its name</p></li>
<li><p><strong>second_attribute</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – Second attribute words list and its name</p></li>
<li><p><strong>with_pvalue</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to calculate the p-value of the
WEAT score (might be computationally expensive)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>WEAT result (score, size effect, Nt, Na and p-value)</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.weat.calc_weat_pleasant_unpleasant_attribute">
<code class="sig-prename descclassname">responsibly.we.weat.</code><code class="sig-name descname">calc_weat_pleasant_unpleasant_attribute</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">first_target</em>, <em class="sig-param">second_target</em>, <em class="sig-param">with_pvalue=True</em>, <em class="sig-param">pvalue_kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/weat.html#calc_weat_pleasant_unpleasant_attribute"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.weat.calc_weat_pleasant_unpleasant_attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>Calc the WEAT result with pleasent vs. unpleasant attributes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding model of <code class="docutils literal notranslate"><span class="pre">gensim.model.KeyedVectors</span></code></p></li>
<li><p><strong>first_target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – First target words list and its name</p></li>
<li><p><strong>second_target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – Second target words list and its name</p></li>
<li><p><strong>with_pvalue</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to calculate the p-value of the
WEAT score (might be computationally expensive)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>WEAT result (score, size effect, Nt, Na and p-value)</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.weat.calc_all_weat">
<code class="sig-prename descclassname">responsibly.we.weat.</code><code class="sig-name descname">calc_all_weat</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">weat_data='caliskan'</em>, <em class="sig-param">filter_by='model'</em>, <em class="sig-param">with_original_finding=False</em>, <em class="sig-param">with_pvalue=True</em>, <em class="sig-param">pvalue_kwargs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/weat.html#calc_all_weat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.weat.calc_all_weat" title="Permalink to this definition">¶</a></dt>
<dd><p>Calc the WEAT results of a word embedding on multiple cases.</p>
<p>Note that for the effect size and pvalue in the WEAT have
entirely different meaning from those reported in IATs (original finding).
Refer to the paper for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding model of <code class="docutils literal notranslate"><span class="pre">gensim.model.KeyedVectors</span></code></p></li>
<li><p><strong>weat_data</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – <p>WEAT cases data.
- If <cite>‘caliskan’</cite> (default) then all</p>
<blockquote>
<div><p>the experiments from the original will be used.</p>
</div></blockquote>
<ul>
<li><p>If an interger, then the specific experiment by index
from the original paper will be used.</p></li>
<li><p>If a interger, then tje specific experiments by indices
from the original paper will be used.</p></li>
</ul>
</p></li>
<li><p><strong>filter_by</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to filter the word lists
by the <cite>model</cite> (<cite>‘model’</cite>)
or by the <cite>remove</cite> key in <cite>weat_data</cite> (<cite>‘data’</cite>).</p></li>
<li><p><strong>with_original_finding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Show the origina</p></li>
<li><p><strong>with_pvalue</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to calculate the p-value of the
WEAT results (might be computationally expensive)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.25.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a> of WEAT results
(score, size effect, Nt, Na and p-value)</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-responsibly.we.utils">
<span id="utilities"></span><h2>Utilities<a class="headerlink" href="#module-responsibly.we.utils" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="responsibly.we.utils.normalize">
<code class="sig-prename descclassname">responsibly.we.utils.</code><code class="sig-name descname">normalize</code><span class="sig-paren">(</span><em class="sig-param">v</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/utils.html#normalize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.utils.normalize" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalize a 1-D vector.</p>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.utils.cosine_similarity">
<code class="sig-prename descclassname">responsibly.we.utils.</code><code class="sig-name descname">cosine_similarity</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">u</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/utils.html#cosine_similarity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.utils.cosine_similarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the cosine similarity between two vectors.</p>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.utils.project_vector">
<code class="sig-prename descclassname">responsibly.we.utils.</code><code class="sig-name descname">project_vector</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">u</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/utils.html#project_vector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.utils.project_vector" title="Permalink to this definition">¶</a></dt>
<dd><p>Projecting the vector v onto direction u.</p>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.utils.reject_vector">
<code class="sig-prename descclassname">responsibly.we.utils.</code><code class="sig-name descname">reject_vector</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">u</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/utils.html#reject_vector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.utils.reject_vector" title="Permalink to this definition">¶</a></dt>
<dd><p>Rejecting the vector v onto direction u.</p>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.utils.project_reject_vector">
<code class="sig-prename descclassname">responsibly.we.utils.</code><code class="sig-name descname">project_reject_vector</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">u</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/utils.html#project_reject_vector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.utils.project_reject_vector" title="Permalink to this definition">¶</a></dt>
<dd><p>Projecting and rejecting the vector v onto direction u.</p>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.utils.project_params">
<code class="sig-prename descclassname">responsibly.we.utils.</code><code class="sig-name descname">project_params</code><span class="sig-paren">(</span><em class="sig-param">u</em>, <em class="sig-param">v</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/utils.html#project_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.utils.project_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Projecting and rejecting the vector v onto direction u with scalar.</p>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.utils.cosine_similarities_by_words">
<code class="sig-prename descclassname">responsibly.we.utils.</code><code class="sig-name descname">cosine_similarities_by_words</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">word</em>, <em class="sig-param">words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/utils.html#cosine_similarities_by_words"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.utils.cosine_similarities_by_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute cosine similarities between a word and a set of other words.</p>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.utils.most_similar">
<code class="sig-prename descclassname">responsibly.we.utils.</code><code class="sig-name descname">most_similar</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">positive=None</em>, <em class="sig-param">negative=None</em>, <em class="sig-param">topn=10</em>, <em class="sig-param">restrict_vocab=None</em>, <em class="sig-param">indexer=None</em>, <em class="sig-param">unrestricted=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/utils.html#most_similar"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.utils.most_similar" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the top-N most similar words.</p>
<p>Positive words contribute positively towards the similarity,
negative words negatively.</p>
<p>This function computes cosine similarity between a simple mean
of the projection weight vectors of the given words and
the vectors for each word in the model.
The function corresponds to the <cite>word-analogy</cite> and <cite>distance</cite>
scripts in the original word2vec implementation.</p>
<p>Based on Gensim implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding model of <code class="docutils literal notranslate"><span class="pre">gensim.model.KeyedVectors</span></code>.</p></li>
<li><p><strong>positive</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of words that contribute positively.</p></li>
<li><p><strong>negative</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a>) – List of words that contribute negatively.</p></li>
<li><p><strong>topn</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of top-N similar words to return.</p></li>
<li><p><strong>restrict_vocab</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Optional integer which limits the
range of vectors
which are searched for most-similar values.
For example, restrict_vocab=10000 would
only check the first 10000 word vectors
in the vocabulary order. (This may be
meaningful if you’ve sorted the vocabulary
by descending frequency.)</p></li>
<li><p><strong>unrestricted</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether to restricted the most
similar words to be not from
the positive or negative word list.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Sequence of (word, similarity).</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-responsibly.we.benchmark">
<span id="word-embedding-benchmarks"></span><h2>Word Embedding Benchmarks<a class="headerlink" href="#module-responsibly.we.benchmark" title="Permalink to this headline">¶</a></h2>
<p>Evaluate word embedding by standard benchmarks.</p>
<dl class="simple">
<dt>Reference:</dt><dd><ul class="simple">
<li><p><a class="reference external" href="https://github.com/kudkudak/word-embeddings-benchmarks">https://github.com/kudkudak/word-embeddings-benchmarks</a></p></li>
</ul>
</dd>
</dl>
<div class="section" id="word-pairs-tasks">
<h3>Word Pairs Tasks<a class="headerlink" href="#word-pairs-tasks" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>The WordSimilarity-353 Test Collection
<a class="reference external" href="http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/">http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/</a></p></li>
<li><p>Rubenstein, H., and Goodenough, J. 1965. Contextual correlates of synonymy
<a class="reference external" href="https://www.seas.upenn.edu/~hansens/conceptSim/">https://www.seas.upenn.edu/~hansens/conceptSim/</a></p></li>
<li><p>Stanford Rare Word (RW) Similarity Dataset
<a class="reference external" href="https://nlp.stanford.edu/~lmthang/morphoNLM/">https://nlp.stanford.edu/~lmthang/morphoNLM/</a></p></li>
<li><p>The Word Relatedness Mturk-771 Test Collection
<a class="reference external" href="http://www2.mta.ac.il/~gideon/datasets/mturk_771.html">http://www2.mta.ac.il/~gideon/datasets/mturk_771.html</a></p></li>
<li><p>The MEN Test Collection
<a class="reference external" href="http://clic.cimec.unitn.it/~elia.bruni/MEN.html">http://clic.cimec.unitn.it/~elia.bruni/MEN.html</a></p></li>
<li><p>SimLex-999
<a class="reference external" href="https://fh295.github.io/simlex.html">https://fh295.github.io/simlex.html</a></p></li>
<li><p>TR9856
<a class="reference external" href="https://www.research.ibm.com/haifa/dept/vst/files/IBM_Debater_(R)_TR9856.v2.zip">https://www.research.ibm.com/haifa/dept/vst/files/IBM_Debater_(R)_TR9856.v2.zip</a></p></li>
</ol>
</div>
<div class="section" id="analogies-tasks">
<h3>Analogies Tasks<a class="headerlink" href="#analogies-tasks" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li><p>Google Analogies (subset of WordRep)
<a class="reference external" href="https://code.google.com/archive/p/word2vec/source">https://code.google.com/archive/p/word2vec/source</a></p></li>
<li><p>MSR - Syntactic Analogies
<a class="reference external" href="http://research.microsoft.com/en-us/projects/rnn/">http://research.microsoft.com/en-us/projects/rnn/</a></p></li>
</ol>
<dl class="function">
<dt id="responsibly.we.benchmark.evaluate_word_pairs">
<code class="sig-prename descclassname">responsibly.we.benchmark.</code><code class="sig-name descname">evaluate_word_pairs</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">kwargs_word_pairs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/benchmark.html#evaluate_word_pairs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.benchmark.evaluate_word_pairs" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate word pairs tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding.</p></li>
<li><p><strong>kwargs_word_pairs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – Kwargs for
evaluate_word_pairs
method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.25.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a> of evaluation results.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.benchmark.evaluate_word_analogies">
<code class="sig-prename descclassname">responsibly.we.benchmark.</code><code class="sig-name descname">evaluate_word_analogies</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">kwargs_word_analogies=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/benchmark.html#evaluate_word_analogies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.benchmark.evaluate_word_analogies" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate word analogies tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding.</p></li>
<li><p><strong>kwargs_word_analogies</strong> – Kwargs for
evaluate_word_analogies
method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(in pandas v0.25.0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a> of evaluation results.</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="responsibly.we.benchmark.evaluate_word_embedding">
<code class="sig-prename descclassname">responsibly.we.benchmark.</code><code class="sig-name descname">evaluate_word_embedding</code><span class="sig-paren">(</span><em class="sig-param">model</em>, <em class="sig-param">kwargs_word_pairs=None</em>, <em class="sig-param">kwargs_word_analogies=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/responsibly/we/benchmark.html#evaluate_word_embedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#responsibly.we.benchmark.evaluate_word_embedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate word pairs tasks and word analogies tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – Word embedding.</p></li>
<li><p><strong>kwargs_word_pairs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – Kwargs fo
evaluate_word_pairs
method.</p></li>
<li><p><strong>kwargs_word_analogies</strong> – Kwargs for
evaluate_word_analogies
method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of DataFrame for the evaluation results.</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Responsibly</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=ResponsiblyAI&repo=responsibly&type=star&v=2&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dataset.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="fairness.html">Classification Fairness</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Word Embedding Bias</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-responsibly.we.bias">Bolukbasi Bias Measure and Debiasing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-responsibly.we.weat">WEAT</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-responsibly.we.utils">Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-responsibly.we.benchmark">Word Embedding Benchmarks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="demos.html">Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="about/contributing.html">For Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="about/changelog.html">Revision History</a></li>
<li class="toctree-l1"><a class="reference internal" href="about/license.html">License</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="fairness.html" title="previous chapter">Classification Fairness</a></li>
      <li>Next: <a href="demos.html" title="next chapter">Demos</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Shlomi Hod.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/word-embedding-bias.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/ResponsiblyAI/responsibly" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>