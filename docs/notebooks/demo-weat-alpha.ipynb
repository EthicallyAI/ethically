{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Word Embedding Association Test, (WEAT) [Alpha Version]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on: Caliskan, A., Bryson, J. J., & Narayanan, A. (2017). [Semantics derived automatically from language corpora contain human-like biases](http://www.cs.bath.ac.uk/~jjb/ftp/CaliskanEtAl-authors-full.pdf). Science, 356(6334), 183-186."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEAT in `ethically` is in a alpha version, and therefore it is not yet in the PyPI release. In order to use this coude, you should install `ethically` from the `feature_weat` branch by:\n",
    "\n",
    "`pip install --upgrade git+https://github.com/EthicallyAI/ethically.git@feature_weat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ethically.we import calc_all_weat\n",
    "from ethically.we.data import load_w2v_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For unzipping, converting and loading Glove and Word2Vec full models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec - Only Lowercase and Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v_small = load_w2v_small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_all_weat(model_w2v_small, filter_by='model', with_original_finding=True,\n",
    "              with_pvalue=True, pvalue_kwargs={'method': 'approximate'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the two next sections, we need the full Glove and Word2Vec words embedding, as used in the original paper. Note that it might take a while to download, extract and load these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove - Common Crawl (840B tokens, 2.2M vocab, cased, 300d vectors, 2.03 GB download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Glove model: http://nlp.stanford.edu/data/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('glove.840B.300d.zip')\n",
    "print('Unzipping...')\n",
    "with ZipFile('glove.840B.300d.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "print('Converting to Word2Vec format...')\n",
    "glove2word2vec('glove.840B.300d.txt', 'glove.840B.300d.w2v.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format('glove.840B.300d.w2v.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_all_weat(glove_model, filter_by='data', with_original_finding=True,\n",
    "              with_pvalue=True, pvalue_kwargs={'method': 'approximate'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from the paper:\n",
    "![](weat_glove.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec - Google News dataset (100B tokens, 3M vocab, cased, 300d vectors, 1.65GB download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Word2Vec model:\n",
    "https://code.google.com/archive/p/word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('GoogleNews-vectors-negative300.bin.gz')\n",
    "print('Unzipping...')\n",
    "with gzip.open('GoogleNews-vectors-negative300.bin.gz', 'r') as f_gz:\n",
    "    with open('GoogleNews-vectors-negative300.bin', 'wb') as f_bin:\n",
    "        shutil.copyfileobj(f_gz, f_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',\n",
    "                                              binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_all_weat(w2v_model, filter_by='model', with_original_finding=True,\n",
    "              with_pvalue=True, pvalue_kwargs={'method': 'approximate'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from the paper:\n",
    "![](weat_w2v.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
