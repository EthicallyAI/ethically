
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>responsibly.we.bias &#8212; Responsibly 0.1.0 documentation</title>
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for responsibly.we.bias</h1><div class="highlight"><pre>
<span></span><span class="c1"># pylint: disable=too-many-lines</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Measuring and adjusting bias in word embedding by Bolukbasi (2016).</span>

<span class="sd">References:</span>
<span class="sd">    - Bolukbasi, T., Chang, K. W., Zou, J. Y., Saligrama, V.,</span>
<span class="sd">      &amp; Kalai, A. T. (2016).</span>
<span class="sd">      `Man is to computer programmer as woman is to homemaker?</span>
<span class="sd">      debiasing word embeddings &lt;https://arxiv.org/abs/1607.06520&gt;`_.</span>
<span class="sd">      In Advances in neural information processing systems</span>
<span class="sd">      (pp. 4349-4357).</span>

<span class="sd">    - The code and data is based on the GitHub repository:</span>
<span class="sd">      https://github.com/tolga-b/debiaswe (MIT License).</span>

<span class="sd">    - Gonen, H., &amp; Goldberg, Y. (2019).</span>
<span class="sd">      `Lipstick on a Pig:</span>
<span class="sd">      Debiasing Methods Cover up Systematic Gender Biases</span>
<span class="sd">      in Word Embeddings But do not Remove Them</span>
<span class="sd">      &lt;https://arxiv.org/abs/1903.03862&gt;`_.</span>
<span class="sd">      arXiv preprint arXiv:1903.03862.</span>

<span class="sd">    - Nissim, M., van Noord, R., van der Goot, R. (2019).</span>
<span class="sd">      `Fair is Better than Sensational: Man is to Doctor</span>
<span class="sd">      as Woman is to Doctor &lt;https://arxiv.org/abs/1905.09866&gt;`_.</span>

<span class="sd">Usage</span>
<span class="sd">~~~~~</span>

<span class="sd">.. code:: python</span>

<span class="sd">   &gt;&gt;&gt; from responsibly.we import GenderBiasWE</span>
<span class="sd">   &gt;&gt;&gt; from gensim import downloader</span>
<span class="sd">   &gt;&gt;&gt; w2v_model = downloader.load(&#39;word2vec-google-news-300&#39;)</span>
<span class="sd">   &gt;&gt;&gt; w2v_gender_bias_we = GenderBiasWE(w2v_model)</span>
<span class="sd">   &gt;&gt;&gt; w2v_gender_bias_we.calc_direct_bias()</span>
<span class="sd">   0.07307904249481942</span>
<span class="sd">   &gt;&gt;&gt; w2v_gender_bias_we.debias()</span>
<span class="sd">   &gt;&gt;&gt; w2v_gender_bias_we.calc_direct_bias()</span>
<span class="sd">   1.7964246601064155e-09</span>

<span class="sd">Types of Bias</span>
<span class="sd">~~~~~~~~~~~~~</span>

<span class="sd">Direct Bias</span>
<span class="sd">^^^^^^^^^^^</span>

<span class="sd">1. Associations</span>
<span class="sd">    Words that are closer to one end (e.g., *he*) than to</span>
<span class="sd">    the other end (*she*).</span>
<span class="sd">    For example, occupational stereotypes (page 7).</span>
<span class="sd">    Calculated by</span>
<span class="sd">    :meth:`~responsibly.we.bias.BiasWordEmbedding.calc_direct_bias`.</span>

<span class="sd">2. Analogies</span>
<span class="sd">    Analogies of *he:x::she:y*.</span>
<span class="sd">    For example analogies exhibiting stereotypes (page 7).</span>
<span class="sd">    Generated by</span>
<span class="sd">    :meth:`~responsibly.we.bias.BiasWordEmbedding.generate_analogies`.</span>


<span class="sd">Indirect Bias</span>
<span class="sd">^^^^^^^^^^^^^</span>

<span class="sd">Projection of a neutral words into a two neutral words direction</span>
<span class="sd">is explained in a great portion by a shared bias direction projection.</span>

<span class="sd">Calculated by</span>
<span class="sd">:meth:`~responsibly.we.bias.BiasWordEmbedding.calc_indirect_bias`</span>
<span class="sd">and</span>
<span class="sd">:meth:`~responsibly.we.bias.GenderBiasWE.generate_closest_words_indirect_bias`.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">pearsonr</span><span class="p">,</span> <span class="n">spearmanr</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="k">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="k">import</span> <span class="n">euclidean_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="k">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="nn">responsibly.consts</span> <span class="k">import</span> <span class="n">RANDOM_STATE</span>
<span class="kn">from</span> <span class="nn">responsibly.utils</span> <span class="k">import</span> <span class="n">_warning_setup</span>
<span class="kn">from</span> <span class="nn">responsibly.we.benchmark</span> <span class="k">import</span> <span class="n">evaluate_word_embedding</span>
<span class="kn">from</span> <span class="nn">responsibly.we.data</span> <span class="k">import</span> <span class="n">BOLUKBASI_DATA</span><span class="p">,</span> <span class="n">OCCUPATION_FEMALE_PRECENTAGE</span>
<span class="kn">from</span> <span class="nn">responsibly.we.utils</span> <span class="k">import</span> <span class="p">(</span>
    <span class="n">assert_gensim_keyed_vectors</span><span class="p">,</span> <span class="n">cosine_similarity</span><span class="p">,</span> <span class="n">generate_one_word_forms</span><span class="p">,</span>
    <span class="n">generate_words_forms</span><span class="p">,</span> <span class="n">get_seed_vector</span><span class="p">,</span> <span class="n">most_similar</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span>
    <span class="n">plot_clustering_as_classification</span><span class="p">,</span> <span class="n">project_params</span><span class="p">,</span> <span class="n">project_reject_vector</span><span class="p">,</span>
    <span class="n">project_vector</span><span class="p">,</span> <span class="n">reject_vector</span><span class="p">,</span> <span class="n">round_to_extreme</span><span class="p">,</span>
    <span class="n">take_two_sides_extreme_sorted</span><span class="p">,</span> <span class="n">update_word_vector</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="k">import</span> <span class="n">tabulate</span>


<span class="n">DIRECTION_METHODS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;single&#39;</span><span class="p">,</span> <span class="s1">&#39;sum&#39;</span><span class="p">,</span> <span class="s1">&#39;pca&#39;</span><span class="p">]</span>
<span class="n">DEBIAS_METHODS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;neutralize&#39;</span><span class="p">,</span> <span class="s1">&#39;hard&#39;</span><span class="p">,</span> <span class="s1">&#39;soft&#39;</span><span class="p">]</span>
<span class="n">FIRST_PC_THRESHOLD</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">MAX_NON_SPECIFIC_EXAMPLES</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;GenderBiasWE&#39;</span><span class="p">,</span> <span class="s1">&#39;BiasWordEmbedding&#39;</span><span class="p">]</span>

<span class="n">_warning_setup</span><span class="p">()</span>


<div class="viewcode-block" id="BiasWordEmbedding"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding">[docs]</a><span class="k">class</span> <span class="nc">BiasWordEmbedding</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Measure and adjust a bias in English word embedding.</span>

<span class="sd">    :param model: Word embedding model of ``gensim.model.KeyedVectors``</span>
<span class="sd">    :param bool only_lower: Whether the word embedding contrains</span>
<span class="sd">                            only lower case words</span>
<span class="sd">    :param bool verbose: Set verbosity</span>
<span class="sd">    :param bool to_normalize: Whether to normalize all the vectors</span>
<span class="sd">                              (recommended!)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">only_lower</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">identify_direction</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">to_normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">assert_gensim_keyed_vectors</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># TODO: this is bad Python, ask someone about it</span>
        <span class="c1"># probably should be a better design</span>
        <span class="c1"># identify_direction doesn&#39;t have any meaning</span>
        <span class="c1"># for the class BiasWordEmbedding</span>
        <span class="c1"># The goal is to force this interfeace of sub-classes.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span> <span class="o">==</span> <span class="vm">__class__</span> <span class="ow">and</span> <span class="n">identify_direction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;identify_direction must be False&#39;</span>
                             <span class="s1">&#39; for an instance of </span><span class="si">{}</span><span class="s1">&#39;</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="vm">__class__</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="c1"># TODO: write unitest for when it is False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">only_lower</span> <span class="o">=</span> <span class="n">only_lower</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">direction</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positive_end</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">negative_end</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">to_normalize</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_sims</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__copy__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">bias_word_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">only_lower</span><span class="p">,</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">,</span>
                                             <span class="n">identify_direction</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">bias_word_embedding</span><span class="o">.</span><span class="n">direction</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">)</span>
        <span class="n">bias_word_embedding</span><span class="o">.</span><span class="n">positive_end</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">positive_end</span><span class="p">)</span>
        <span class="n">bias_word_embedding</span><span class="o">.</span><span class="n">negative_end</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">negative_end</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">bias_word_embedding</span>

    <span class="k">def</span> <span class="nf">__deepcopy__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="p">):</span>
        <span class="n">bias_word_embedding</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">bias_word_embedding</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">bias_word_embedding</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">bias_word_embedding</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>

    <span class="k">def</span> <span class="nf">_filter_words_by_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_is_direction_identified</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;The direction was not identified&#39;</span>
                               <span class="s1">&#39; for this </span><span class="si">{}</span><span class="s1"> instance&#39;</span>
                               <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>

    <span class="c1"># There is a mistake in the article</span>
    <span class="c1"># it is written (section 5.1):</span>
    <span class="c1"># &quot;To identify the gender subspace, we took the ten gender pair difference</span>
    <span class="c1"># vectors and computed its principal components (PCs)&quot;</span>
    <span class="c1"># however in the source code:</span>
    <span class="c1"># https://github.com/tolga-b/debiaswe/blob/10277b23e187ee4bd2b6872b507163ef4198686b/debiaswe/we.py#L235-L245</span>
    <span class="k">def</span> <span class="nf">_identify_subspace_by_pca</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">definitional_pairs</span><span class="p">,</span> <span class="n">n_components</span><span class="p">):</span>
        <span class="n">matrix</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">word1</span><span class="p">,</span> <span class="n">word2</span> <span class="ow">in</span> <span class="n">definitional_pairs</span><span class="p">:</span>
            <span class="n">vector1</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">word1</span><span class="p">])</span>
            <span class="n">vector2</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">word2</span><span class="p">])</span>

            <span class="n">center</span> <span class="o">=</span> <span class="p">(</span><span class="n">vector1</span> <span class="o">+</span> <span class="n">vector2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

            <span class="n">matrix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vector1</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span>
            <span class="n">matrix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vector2</span> <span class="o">-</span> <span class="n">center</span><span class="p">)</span>

        <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
        <span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
            <span class="n">table</span> <span class="o">=</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">,</span>
                       <span class="s1">&#39;Explained Variance Ratio&#39;</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">pca</span>

    <span class="c1"># TODO: add the SVD method from section 6 step 1</span>
    <span class="c1"># It seems there is a mistake there, I think it is the same as PCA</span>
    <span class="c1"># just with replacing it with SVD</span>
    <span class="k">def</span> <span class="nf">_identify_direction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">positive_end</span><span class="p">,</span> <span class="n">negative_end</span><span class="p">,</span>
                            <span class="n">definitional</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;pca&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">DIRECTION_METHODS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;method should be one of </span><span class="si">{}</span><span class="s1">, </span><span class="si">{}</span><span class="s1"> was given&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">DIRECTION_METHODS</span><span class="p">,</span> <span class="n">method</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">positive_end</span> <span class="o">==</span> <span class="n">negative_end</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;positive_end and negative_end&#39;</span>
                             <span class="s1">&#39;should be different, and not the same &quot;</span><span class="si">{}</span><span class="s1">&quot;&#39;</span>
                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">positive_end</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Identify direction using </span><span class="si">{}</span><span class="s1"> method...&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">method</span><span class="p">))</span>

        <span class="n">direction</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;single&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Positive definitional end:&#39;</span><span class="p">,</span> <span class="n">definitional</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Negative definitional end:&#39;</span><span class="p">,</span> <span class="n">definitional</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">direction</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">definitional</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
                                  <span class="o">-</span> <span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">definitional</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
            <span class="n">group1_sum_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
                                        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">definitional</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">group2_sum_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
                                        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">definitional</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="n">diff_vector</span> <span class="o">=</span> <span class="p">(</span><span class="n">normalize</span><span class="p">(</span><span class="n">group1_sum_vector</span><span class="p">)</span>
                           <span class="o">-</span> <span class="n">normalize</span><span class="p">(</span><span class="n">group2_sum_vector</span><span class="p">))</span>

            <span class="n">direction</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">diff_vector</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;pca&#39;</span><span class="p">:</span>
            <span class="n">pca</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_identify_subspace_by_pca</span><span class="p">(</span><span class="n">definitional</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">FIRST_PC_THRESHOLD</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;The Explained variance&#39;</span>
                                   <span class="s1">&#39;of the first principal component should be&#39;</span>
                                   <span class="s1">&#39;at least </span><span class="si">{}</span><span class="s1">, but it is </span><span class="si">{}</span><span class="s1">&#39;</span>
                                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">FIRST_PC_THRESHOLD</span><span class="p">,</span>
                                           <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="n">direction</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># if direction is opposite (e.g. we cannot control</span>
            <span class="c1"># what the PCA will return)</span>
            <span class="n">ends_diff_projection</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">((</span><span class="bp">self</span><span class="p">[</span><span class="n">positive_end</span><span class="p">]</span>
                                                      <span class="o">-</span> <span class="bp">self</span><span class="p">[</span><span class="n">negative_end</span><span class="p">]),</span>
                                                     <span class="n">direction</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ends_diff_projection</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">direction</span> <span class="o">=</span> <span class="o">-</span><span class="n">direction</span>  <span class="c1"># pylint: disable=invalid-unary-operand-type</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">direction</span> <span class="o">=</span> <span class="n">direction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positive_end</span> <span class="o">=</span> <span class="n">positive_end</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">negative_end</span> <span class="o">=</span> <span class="n">negative_end</span>

<div class="viewcode-block" id="BiasWordEmbedding.project_on_direction"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.project_on_direction">[docs]</a>    <span class="k">def</span> <span class="nf">project_on_direction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Project the normalized vector of the word on the direction.</span>

<span class="sd">        :param str word: The word tor project</span>
<span class="sd">        :return float: The projection scalar</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_direction_identified</span><span class="p">()</span>

        <span class="n">vector</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="n">projection_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cosine_similarities</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">,</span>
                                                          <span class="p">[</span><span class="n">vector</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">projection_score</span></div>

    <span class="k">def</span> <span class="nf">_calc_projection_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_direction_identified</span><span class="p">()</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="n">words</span><span class="p">})</span>

        <span class="c1"># TODO: maybe using cosine_similarities on all the vectors?</span>
        <span class="c1"># it might be faster</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;projection&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_on_direction</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;projection&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span>

<div class="viewcode-block" id="BiasWordEmbedding.calc_projection_data"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.calc_projection_data">[docs]</a>    <span class="k">def</span> <span class="nf">calc_projection_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate projection, projected and rejected vectors of a words list.</span>

<span class="sd">        :param list words: List of words</span>
<span class="sd">        :return: :class:`pandas.DataFrame` of the projection,</span>
<span class="sd">                 projected and rejected vectors of the words list</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">projection_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="n">vector</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
            <span class="n">projection</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">project_on_direction</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
            <span class="n">normalized_vector</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>

            <span class="p">(</span><span class="n">projection</span><span class="p">,</span>
             <span class="n">projected_vector</span><span class="p">,</span>
             <span class="n">rejected_vector</span><span class="p">)</span> <span class="o">=</span> <span class="n">project_params</span><span class="p">(</span><span class="n">normalized_vector</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">)</span>

            <span class="n">projection_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="n">word</span><span class="p">,</span>
                                    <span class="s1">&#39;vector&#39;</span><span class="p">:</span> <span class="n">vector</span><span class="p">,</span>
                                    <span class="s1">&#39;projection&#39;</span><span class="p">:</span> <span class="n">projection</span><span class="p">,</span>
                                    <span class="s1">&#39;projected_vector&#39;</span><span class="p">:</span> <span class="n">projected_vector</span><span class="p">,</span>
                                    <span class="s1">&#39;rejected_vector&#39;</span><span class="p">:</span> <span class="n">rejected_vector</span><span class="p">})</span>

        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">projection_data</span><span class="p">)</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.plot_projection_scores"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.plot_projection_scores">[docs]</a>    <span class="k">def</span> <span class="nf">plot_projection_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="p">,</span> <span class="n">n_extreme</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                               <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis_projection_step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Plot the projection scalar of words on the direction.</span>

<span class="sd">        :param list words: The words tor project</span>
<span class="sd">        :param int or None n_extreme: The number of extreme words to show</span>
<span class="sd">        :return: The ax object of the plot</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_direction_identified</span><span class="p">()</span>

        <span class="n">projections_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_projection_scores</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
        <span class="n">projections_df</span><span class="p">[</span><span class="s1">&#39;projection&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">projections_df</span><span class="p">[</span><span class="s1">&#39;projection&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_extreme</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">projections_df</span> <span class="o">=</span> <span class="n">take_two_sides_extreme_sorted</span><span class="p">(</span><span class="n">projections_df</span><span class="p">,</span>
                                                           <span class="n">n_extreme</span><span class="o">=</span><span class="n">n_extreme</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">axis_projection_step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">axis_projection_step</span> <span class="o">=</span> <span class="mf">0.1</span>

        <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;RdBu&#39;</span><span class="p">)</span>
        <span class="n">projections_df</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">projections_df</span><span class="p">[</span><span class="s1">&#39;projection&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
                                   <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">cmap</span><span class="p">))</span>

        <span class="n">most_extream_projection</span> <span class="o">=</span> <span class="p">(</span><span class="n">projections_df</span><span class="p">[</span><span class="s1">&#39;projection&#39;</span><span class="p">]</span>
                                   <span class="o">.</span><span class="n">abs</span><span class="p">()</span>
                                   <span class="o">.</span><span class="n">max</span><span class="p">()</span>
                                   <span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;projection&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;word&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">projections_df</span><span class="p">,</span>
                    <span class="n">palette</span><span class="o">=</span><span class="n">projections_df</span><span class="p">[</span><span class="s1">&#39;color&#39;</span><span class="p">])</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">most_extream_projection</span><span class="p">,</span>
                             <span class="n">most_extream_projection</span> <span class="o">+</span> <span class="n">axis_projection_step</span><span class="p">,</span>
                             <span class="n">axis_projection_step</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;← </span><span class="si">{}</span><span class="s1"> </span><span class="si">{}</span><span class="s1"> </span><span class="si">{}</span><span class="s1"> →&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">negative_end</span><span class="p">,</span>
                                        <span class="s1">&#39; &#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">positive_end</span><span class="p">))</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Direction Projection&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Words&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ax</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.plot_dist_projections_on_direction"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.plot_dist_projections_on_direction">[docs]</a>    <span class="k">def</span> <span class="nf">plot_dist_projections_on_direction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word_groups</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Plot the projection scalars distribution on the direction.</span>

<span class="sd">        :param dict word_groups word: The groups to projects</span>
<span class="sd">        :return float: The ax object of the plot</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">names</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_groups</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">word_groups</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> (#</span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))</span>
            <span class="n">vectors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
            <span class="n">projections</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">cosine_similarities</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">,</span>
                                                         <span class="n">vectors</span><span class="p">)</span>
            <span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">projections</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;← </span><span class="si">{}</span><span class="s1"> </span><span class="si">{}</span><span class="s1"> </span><span class="si">{}</span><span class="s1"> →&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">negative_end</span><span class="p">,</span>
                                        <span class="s1">&#39; &#39;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">positive_end</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Direction Projection&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center left&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">ax</span></div>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_calc_bias_across_word_embeddings</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span>
                                          <span class="n">word_embedding_bias_dict</span><span class="p">,</span>
                                          <span class="n">words</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate to projections and rho of words for two word embeddings.</span>

<span class="sd">        :param dict word_embedding_bias_dict: ``WordsEmbeddingBias`` objects</span>
<span class="sd">                                               as values,</span>
<span class="sd">                                               and their names as keys.</span>
<span class="sd">        :param list words: Words to be projected.</span>
<span class="sd">        :return tuple: Projections and spearman rho.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: disable=W0212</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_embedding_bias_dict</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;Support only in two&#39;</span>\
                                                    <span class="s1">&#39;word embeddings&#39;</span>

        <span class="n">intersection_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span>
                              <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">word</span> <span class="ow">in</span> <span class="n">web</span>
                                     <span class="k">for</span> <span class="n">web</span> <span class="ow">in</span> <span class="p">(</span><span class="n">word_embedding_bias_dict</span>
                                                 <span class="o">.</span><span class="n">values</span><span class="p">()))]</span>

        <span class="n">projections</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">web</span><span class="o">.</span><span class="n">_calc_projection_scores</span><span class="p">(</span><span class="n">intersection_words</span><span class="p">)[</span><span class="s1">&#39;projection&#39;</span><span class="p">]</span>  <span class="c1"># pylint: disable=C0301</span>
                       <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">web</span> <span class="ow">in</span> <span class="n">word_embedding_bias_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">projections</span><span class="p">)</span>
        <span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">intersection_words</span>

        <span class="n">rho</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">spearmanr</span><span class="p">(</span><span class="o">*</span><span class="n">df</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">rho</span>

<div class="viewcode-block" id="BiasWordEmbedding.plot_bias_across_word_embeddings"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.plot_bias_across_word_embeddings">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">plot_bias_across_word_embeddings</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">word_embedding_bias_dict</span><span class="p">,</span>
                                         <span class="n">words</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scatter_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the projections of same words of two word mbeddings.</span>

<span class="sd">        :param dict word_embedding_bias_dict: ``WordsEmbeddingBias`` objects</span>
<span class="sd">                                               as values,</span>
<span class="sd">                                               and their names as keys.</span>
<span class="sd">        :param list words: Words to be projected.</span>
<span class="sd">        :param scatter_kwargs: Kwargs for matplotlib.pylab.scatter.</span>
<span class="sd">        :type scatter_kwargs: dict or None</span>
<span class="sd">        :return: The ax object of the plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: disable=W0212</span>

        <span class="n">df</span><span class="p">,</span> <span class="n">rho</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_calc_bias_across_word_embeddings</span><span class="p">(</span><span class="n">word_embedding_bias_dict</span><span class="p">,</span>  <span class="c1"># pylint: disable=C0301</span>
                                                        <span class="n">words</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">scatter_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scatter_kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">name1</span><span class="p">,</span> <span class="n">name2</span> <span class="o">=</span> <span class="n">word_embedding_bias_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">name1</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">name2</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="o">**</span><span class="n">scatter_kwargs</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Bias Across Word Embeddings&#39;</span>
                  <span class="s1">&#39;(Spearman Rho = </span><span class="si">{:0.2f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rho</span><span class="p">))</span>

        <span class="n">negative_end</span> <span class="o">=</span> <span class="n">word_embedding_bias_dict</span><span class="p">[</span><span class="n">name1</span><span class="p">]</span><span class="o">.</span><span class="n">negative_end</span>
        <span class="n">positive_end</span> <span class="o">=</span> <span class="n">word_embedding_bias_dict</span><span class="p">[</span><span class="n">name1</span><span class="p">]</span><span class="o">.</span><span class="n">positive_end</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;← </span><span class="si">{}</span><span class="s1">     </span><span class="si">{}</span><span class="s1">     </span><span class="si">{}</span><span class="s1"> →&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">negative_end</span><span class="p">,</span>
                                                 <span class="n">name1</span><span class="p">,</span>
                                                 <span class="n">positive_end</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;← </span><span class="si">{}</span><span class="s1">     </span><span class="si">{}</span><span class="s1">     </span><span class="si">{}</span><span class="s1"> →&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">negative_end</span><span class="p">,</span>
                                                 <span class="n">name2</span><span class="p">,</span>
                                                 <span class="n">positive_end</span><span class="p">))</span>

        <span class="n">ax_min</span> <span class="o">=</span> <span class="n">round_to_extreme</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
        <span class="n">ax_max</span> <span class="o">=</span> <span class="n">round_to_extreme</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">ax_min</span><span class="p">,</span> <span class="n">ax_max</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ax_min</span><span class="p">,</span> <span class="n">ax_max</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ax</span></div>

    <span class="c1"># TODO: refactor for speed and clarity</span>
<div class="viewcode-block" id="BiasWordEmbedding.generate_analogies"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.generate_analogies">[docs]</a>    <span class="k">def</span> <span class="nf">generate_analogies</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_analogies</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="s1">&#39;ends&#39;</span><span class="p">,</span>
                           <span class="n">multiple</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">delta</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">restrict_vocab</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span>
                           <span class="n">unrestricted</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate analogies based on a seed vector.</span>

<span class="sd">        x - y ~ seed vector.</span>
<span class="sd">        or a:x::b:y when a-b ~ seed vector.</span>

<span class="sd">        The seed vector can be defined by two word ends,</span>
<span class="sd">        or by the bias direction.</span>

<span class="sd">        ``delta`` is used for semantically coherent. Default vale of 1</span>
<span class="sd">        corresponds to an angle &lt;= pi/3.</span>


<span class="sd">        There is criticism regarding generating analogies</span>
<span class="sd">        when used with `unstricted=False` and not ignoring analogies</span>
<span class="sd">        with `match` column equal to `False`.</span>
<span class="sd">        Tolga&#39;s technique of generating analogies, as implemented in this</span>
<span class="sd">        method, is limited inherently to analogies with x != y, which may</span>
<span class="sd">        be force &quot;fake&quot; bias analogies.</span>

<span class="sd">        See:</span>

<span class="sd">        - Nissim, M., van Noord, R., van der Goot, R. (2019).</span>
<span class="sd">          `Fair is Better than Sensational: Man is to Doctor</span>
<span class="sd">          as Woman is to Doctor &lt;https://arxiv.org/abs/1905.09866&gt;`_.</span>

<span class="sd">        :param seed: The definition of the seed vector.</span>
<span class="sd">                     Either by a tuple of two word ends,</span>
<span class="sd">                     or by `&#39;ends` for the pre-defined ends</span>
<span class="sd">                     or by `&#39;direction&#39;` for the pre-defined direction vector.</span>
<span class="sd">        :param int n_analogies: Number of analogies to generate.</span>
<span class="sd">        :param bool multiple: Whether to allow multiple appearances of a word</span>
<span class="sd">                              in the analogies.</span>
<span class="sd">        :param float delta: Threshold for semantic similarity.</span>
<span class="sd">                            The maximal distance between x and y.</span>
<span class="sd">        :param int restrict_vocab: The vocabulary size to use.</span>
<span class="sd">        :param bool unrestricted: Whether to validate the generated analogies</span>
<span class="sd">                                  with unrestricted `most_similar`.</span>
<span class="sd">        :return: Data Frame of analogies (x, y), their distances,</span>
<span class="sd">                 and their cosine similarity scores</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: disable=C0301,R0914</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">unrestricted</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Not Using unrestricted most_similar &#39;</span>
                          <span class="s1">&#39;may introduce fake biased analogies.&#39;</span><span class="p">)</span>

        <span class="p">(</span><span class="n">seed_vector</span><span class="p">,</span>
         <span class="n">positive_end</span><span class="p">,</span>
         <span class="n">negative_end</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_seed_vector</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="n">restrict_vocab_vectors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vectors</span><span class="p">[:</span><span class="n">restrict_vocab</span><span class="p">]</span>

        <span class="n">normalized_vectors</span> <span class="o">=</span> <span class="p">(</span><span class="n">restrict_vocab_vectors</span>
                              <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">restrict_vocab_vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">])</span>

        <span class="n">pairs_distances</span> <span class="o">=</span> <span class="n">euclidean_distances</span><span class="p">(</span><span class="n">normalized_vectors</span><span class="p">,</span> <span class="n">normalized_vectors</span><span class="p">)</span>

        <span class="c1"># `pairs_distances` must be not-equal to zero</span>
        <span class="c1"># otherwise, x-y will be the zero vector, and every cosine similarity</span>
        <span class="c1"># will be equal to zero.</span>
        <span class="c1"># This cause to the **limitation** of this method which enforce a not-same</span>
        <span class="c1"># words for x and y.</span>
        <span class="n">pairs_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">pairs_distances</span> <span class="o">&lt;</span> <span class="n">delta</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">pairs_distances</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">pairs_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">pairs_mask</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="n">x_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">normalized_vectors</span><span class="p">,</span> <span class="n">pairs_indices</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">y_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">normalized_vectors</span><span class="p">,</span> <span class="n">pairs_indices</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">x_minus_y_vectors</span> <span class="o">=</span> <span class="n">x_vectors</span> <span class="o">-</span> <span class="n">y_vectors</span>
        <span class="n">normalized_x_minus_y_vectors</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_minus_y_vectors</span>
                                        <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_minus_y_vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">])</span>

        <span class="n">cos_distances</span> <span class="o">=</span> <span class="n">normalized_x_minus_y_vectors</span> <span class="o">@</span> <span class="n">seed_vector</span>

        <span class="n">sorted_cos_distances_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">cos_distances</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">sorted_cos_distances_indices_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">sorted_cos_distances_indices</span><span class="p">)</span>

        <span class="n">analogies</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">generated_words_x</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">generated_words_y</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">analogies</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">n_analogies</span><span class="p">:</span>
            <span class="n">cos_distance_index</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">sorted_cos_distances_indices_iter</span><span class="p">)</span>
            <span class="n">paris_index</span> <span class="o">=</span> <span class="n">pairs_indices</span><span class="p">[</span><span class="n">cos_distance_index</span><span class="p">]</span>
            <span class="n">word_x</span><span class="p">,</span> <span class="n">word_y</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                              <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">paris_index</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">multiple</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">multiple</span>
                            <span class="ow">and</span> <span class="p">(</span><span class="n">word_x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">generated_words_x</span>
                                 <span class="ow">and</span> <span class="n">word_y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">generated_words_y</span><span class="p">)):</span>

                <span class="n">analogy</span> <span class="o">=</span> <span class="p">({</span><span class="n">positive_end</span><span class="p">:</span> <span class="n">word_x</span><span class="p">,</span>
                            <span class="n">negative_end</span><span class="p">:</span> <span class="n">word_y</span><span class="p">,</span>
                            <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="n">cos_distances</span><span class="p">[</span><span class="n">cos_distance_index</span><span class="p">],</span>
                            <span class="s1">&#39;distance&#39;</span><span class="p">:</span> <span class="n">pairs_distances</span><span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">paris_index</span><span class="p">)]})</span>

                <span class="n">generated_words_x</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word_x</span><span class="p">)</span>
                <span class="n">generated_words_y</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word_y</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">unrestricted</span><span class="p">:</span>
                    <span class="n">most_x</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">word</span>
                                  <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">most_similar</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                                                              <span class="p">[</span><span class="n">word_y</span><span class="p">,</span> <span class="n">positive_end</span><span class="p">],</span>
                                                              <span class="p">[</span><span class="n">negative_end</span><span class="p">]))</span>
                    <span class="n">most_y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">word</span>
                                  <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">most_similar</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                                                              <span class="p">[</span><span class="n">word_x</span><span class="p">,</span> <span class="n">negative_end</span><span class="p">],</span>
                                                              <span class="p">[</span><span class="n">positive_end</span><span class="p">]))</span>

                    <span class="n">analogy</span><span class="p">[</span><span class="s1">&#39;most_x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">most_x</span>
                    <span class="n">analogy</span><span class="p">[</span><span class="s1">&#39;most_y&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">most_y</span>
                    <span class="n">analogy</span><span class="p">[</span><span class="s1">&#39;match&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">((</span><span class="n">word_x</span> <span class="o">==</span> <span class="n">most_x</span><span class="p">)</span>
                                        <span class="ow">and</span> <span class="p">(</span><span class="n">word_y</span> <span class="o">==</span> <span class="n">most_y</span><span class="p">))</span>

                <span class="n">analogies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">analogy</span><span class="p">)</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">analogies</span><span class="p">)</span>

        <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">positive_end</span><span class="p">,</span> <span class="n">negative_end</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">unrestricted</span><span class="p">:</span>
            <span class="n">columns</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;most_x&#39;</span><span class="p">,</span> <span class="s1">&#39;most_y&#39;</span><span class="p">,</span> <span class="s1">&#39;match&#39;</span><span class="p">])</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">df</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.calc_direct_bias"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.calc_direct_bias">[docs]</a>    <span class="k">def</span> <span class="nf">calc_direct_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neutral_words</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate the direct bias.</span>

<span class="sd">        Based on the projection of neutral words on the direction.</span>

<span class="sd">        :param list neutral_words: List of neutral words</span>
<span class="sd">        :param c: Strictness of bias measuring</span>
<span class="sd">        :type c: float or None</span>
<span class="sd">        :return: The direct bias</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">c</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">c</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">projections</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_projection_scores</span><span class="p">(</span><span class="n">neutral_words</span><span class="p">)[</span><span class="s1">&#39;projection&#39;</span><span class="p">]</span>
        <span class="n">direct_bias_terms</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">projections</span><span class="p">)</span> <span class="o">**</span> <span class="n">c</span>
        <span class="n">direct_bias</span> <span class="o">=</span> <span class="n">direct_bias_terms</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">neutral_words</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">direct_bias</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.calc_indirect_bias"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.calc_indirect_bias">[docs]</a>    <span class="k">def</span> <span class="nf">calc_indirect_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word1</span><span class="p">,</span> <span class="n">word2</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate the indirect bias between two words.</span>

<span class="sd">        Based on the amount of shared projection of the words on the direction.</span>

<span class="sd">        Also called PairBias.</span>
<span class="sd">        :param str word1: First word</span>
<span class="sd">        :param str word2: Second word</span>
<span class="sd">        :type c: float or None</span>
<span class="sd">        :return The indirect bias between the two words</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_direction_identified</span><span class="p">()</span>

        <span class="n">vector1</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">word1</span><span class="p">])</span>
        <span class="n">vector2</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">word2</span><span class="p">])</span>

        <span class="n">perpendicular_vector1</span> <span class="o">=</span> <span class="n">reject_vector</span><span class="p">(</span><span class="n">vector1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">)</span>
        <span class="n">perpendicular_vector2</span> <span class="o">=</span> <span class="n">reject_vector</span><span class="p">(</span><span class="n">vector2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">)</span>

        <span class="n">inner_product</span> <span class="o">=</span> <span class="n">vector1</span> <span class="o">@</span> <span class="n">vector2</span>
        <span class="n">perpendicular_similarity</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">perpendicular_vector1</span><span class="p">,</span>
                                                     <span class="n">perpendicular_vector2</span><span class="p">)</span>

        <span class="n">indirect_bias</span> <span class="o">=</span> <span class="p">((</span><span class="n">inner_product</span> <span class="o">-</span> <span class="n">perpendicular_similarity</span><span class="p">)</span>
                         <span class="o">/</span> <span class="n">inner_product</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">indirect_bias</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.generate_closest_words_indirect_bias"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.generate_closest_words_indirect_bias">[docs]</a>    <span class="k">def</span> <span class="nf">generate_closest_words_indirect_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                             <span class="n">neutral_positive_end</span><span class="p">,</span>
                                             <span class="n">neutral_negative_end</span><span class="p">,</span>
                                             <span class="n">words</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_extreme</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate closest words to a neutral direction and their indirect bias.</span>

<span class="sd">        The direction of the neutral words is used to find</span>
<span class="sd">        the most extreme words.</span>
<span class="sd">        The indirect bias is calculated between the most extreme words</span>
<span class="sd">        and the closest end.</span>

<span class="sd">        :param str neutral_positive_end: A word that define the positive side</span>
<span class="sd">                                         of the neutral direction.</span>
<span class="sd">        :param str neutral_negative_end: A word that define the negative side</span>
<span class="sd">                                         of the neutral direction.</span>
<span class="sd">        :param list words: List of words to project on the neutral direction.</span>
<span class="sd">        :param int n_extreme: The number for the most extreme words</span>
<span class="sd">                              (positive and negative) to show.</span>
<span class="sd">        :return: Data Frame of the most extreme words</span>
<span class="sd">                 with their projection scores and indirect biases.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">neutral_direction</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">neutral_positive_end</span><span class="p">]</span>
                                      <span class="o">-</span> <span class="bp">self</span><span class="p">[</span><span class="n">neutral_negative_end</span><span class="p">])</span>

        <span class="n">vectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">])</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
        <span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([{</span><span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="n">word</span><span class="p">,</span>
                             <span class="s1">&#39;projection&#39;</span><span class="p">:</span> <span class="n">vector</span> <span class="o">@</span> <span class="n">neutral_direction</span><span class="p">}</span>
                            <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">vector</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">vectors</span><span class="p">)])</span>
              <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;projection&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">take_two_sides_extreme_sorted</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">n_extreme</span><span class="p">,</span>
                                           <span class="s1">&#39;end&#39;</span><span class="p">,</span>
                                           <span class="n">neutral_positive_end</span><span class="p">,</span>
                                           <span class="n">neutral_negative_end</span><span class="p">)</span>

        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;indirect_bias&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">r</span><span class="p">:</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">calc_indirect_bias</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="s1">&#39;word&#39;</span><span class="p">],</span>
                                                               <span class="n">r</span><span class="p">[</span><span class="s1">&#39;end&#39;</span><span class="p">]),</span>
                                       <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="s1">&#39;word&#39;</span><span class="p">])</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;projection&#39;</span><span class="p">,</span> <span class="s1">&#39;indirect_bias&#39;</span><span class="p">]]</span>

        <span class="k">return</span> <span class="n">df</span></div>

    <span class="k">def</span> <span class="nf">_extract_neutral_words</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">specific_words</span><span class="p">):</span>
        <span class="n">extended_specific_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="c1"># because or specific_full data was trained on partial word embedding</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">specific_words</span><span class="p">:</span>
            <span class="n">extended_specific_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
            <span class="n">extended_specific_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
            <span class="n">extended_specific_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">upper</span><span class="p">())</span>
            <span class="n">extended_specific_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">title</span><span class="p">())</span>

        <span class="n">neutral_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vocab</span>
                         <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">extended_specific_words</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">neutral_words</span>

    <span class="k">def</span> <span class="nf">_neutralize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neutral_words</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_direction_identified</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
            <span class="n">neutral_words_iter</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">neutral_words</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">neutral_words_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">neutral_words</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">neutral_words_iter</span><span class="p">:</span>
            <span class="n">neutralized_vector</span> <span class="o">=</span> <span class="n">reject_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">],</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">)</span>
            <span class="n">update_word_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">neutralized_vector</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_sims</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_equalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">equality_sets</span><span class="p">):</span>
        <span class="c1"># pylint: disable=R0914</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_is_direction_identified</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
            <span class="n">words_data</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">equality_set_index</span><span class="p">,</span> <span class="n">equality_set_words</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">equality_sets</span><span class="p">):</span>
            <span class="n">equality_set_vectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
                                    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">equality_set_words</span><span class="p">]</span>
            <span class="n">center</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">equality_set_vectors</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">(</span><span class="n">projected_center</span><span class="p">,</span>
             <span class="n">rejected_center</span><span class="p">)</span> <span class="o">=</span> <span class="n">project_reject_vector</span><span class="p">(</span><span class="n">center</span><span class="p">,</span>
                                                      <span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">)</span>
            <span class="n">scaling</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">rejected_center</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">vector</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">equality_set_words</span><span class="p">,</span> <span class="n">equality_set_vectors</span><span class="p">):</span>
                <span class="n">projected_vector</span> <span class="o">=</span> <span class="n">project_vector</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">)</span>

                <span class="n">projected_part</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">projected_vector</span> <span class="o">-</span> <span class="n">projected_center</span><span class="p">)</span>

                <span class="c1"># In the code it is different of Bolukbasi</span>
                <span class="c1"># It behaves the same only for equality_sets</span>
                <span class="c1"># with size of 2 (pairs) - not sure!</span>
                <span class="c1"># However, my code is the same as the article</span>
                <span class="c1"># equalized_vector = rejected_center + scaling * self.direction</span>
                <span class="c1"># https://github.com/tolga-b/debiaswe/blob/10277b23e187ee4bd2b6872b507163ef4198686b/debiaswe/debias.py#L36-L37</span>
                <span class="c1"># For pairs, projected_part_vector1 == -projected_part_vector2,</span>
                <span class="c1"># and this is the same as</span>
                <span class="c1"># projected_part_vector1 == self.direction</span>
                <span class="n">equalized_vector</span> <span class="o">=</span> <span class="n">rejected_center</span> <span class="o">+</span> <span class="n">scaling</span> <span class="o">*</span> <span class="n">projected_part</span>

                <span class="n">update_word_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">equalized_vector</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
                    <span class="n">words_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s1">&#39;equality_set_index&#39;</span><span class="p">:</span> <span class="n">equality_set_index</span><span class="p">,</span>
                        <span class="s1">&#39;word&#39;</span><span class="p">:</span> <span class="n">word</span><span class="p">,</span>
                        <span class="s1">&#39;scaling&#39;</span><span class="p">:</span> <span class="n">scaling</span><span class="p">,</span>
                        <span class="s1">&#39;projected_scalar&#39;</span><span class="p">:</span> <span class="n">vector</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">,</span>
                        <span class="s1">&#39;equalized_projected_scalar&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">equalized_vector</span>
                                                       <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">direction</span><span class="p">),</span>
                    <span class="p">})</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Equalize Words Data &#39;</span>
                  <span class="s1">&#39;(all equal for 1-dim bias space (direction):&#39;</span><span class="p">)</span>
            <span class="n">words_data_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">words_data</span><span class="p">)</span>
                             <span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s1">&#39;equality_set_index&#39;</span><span class="p">,</span> <span class="s1">&#39;word&#39;</span><span class="p">]))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">words_data_df</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s1">&#39;keys&#39;</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">init_sims</span><span class="p">(</span><span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_generate_pair_candidates</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pairs</span><span class="p">):</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="k">return</span> <span class="p">{(</span><span class="n">candidate1</span><span class="p">,</span> <span class="n">candidate2</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">word1</span><span class="p">,</span> <span class="n">word2</span> <span class="ow">in</span> <span class="n">pairs</span>
                <span class="k">for</span> <span class="n">candidate1</span><span class="p">,</span> <span class="n">candidate2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">generate_one_word_forms</span><span class="p">(</span><span class="n">word1</span><span class="p">),</span>
                                                  <span class="n">generate_one_word_forms</span><span class="p">(</span><span class="n">word2</span><span class="p">))</span>
                <span class="k">if</span> <span class="n">candidate1</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">and</span> <span class="n">candidate2</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">}</span>

<div class="viewcode-block" id="BiasWordEmbedding.debias"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.debias">[docs]</a>    <span class="k">def</span> <span class="nf">debias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;hard&#39;</span><span class="p">,</span> <span class="n">neutral_words</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">equality_sets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Debias the word embedding.</span>

<span class="sd">        :param str method: The method of debiasing.</span>
<span class="sd">        :param list neutral_words: List of neutral words</span>
<span class="sd">                                   for the neutralize step</span>
<span class="sd">        :param list equality_sets: List of equality sets,</span>
<span class="sd">                                   for the equalize step.</span>
<span class="sd">                                   The sets represent the direction.</span>
<span class="sd">        :param bool inplace: Whether to debias the object inplace</span>
<span class="sd">                             or return a new one</span>

<span class="sd">        .. warning::</span>

<span class="sd">          After calling `debias`,</span>
<span class="sd">          all the vectors of the word embedding</span>
<span class="sd">          will be normalized to unit length.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># pylint: disable=W0212</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="n">bias_word_embedding</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bias_word_embedding</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">DEBIAS_METHODS</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;method should be one of </span><span class="si">{}</span><span class="s1">, </span><span class="si">{}</span><span class="s1"> was given&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">DEBIAS_METHODS</span><span class="p">,</span> <span class="n">method</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;hard&#39;</span><span class="p">,</span> <span class="s1">&#39;neutralize&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Neutralize...&#39;</span><span class="p">)</span>
            <span class="n">bias_word_embedding</span><span class="o">.</span><span class="n">_neutralize</span><span class="p">(</span><span class="n">neutral_words</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;hard&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Equalize...&#39;</span><span class="p">)</span>

            <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">equality_set</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                       <span class="k">for</span> <span class="n">equality_set</span> <span class="ow">in</span> <span class="n">equality_sets</span><span class="p">),</span> \
                   <span class="s1">&#39;Currently supporting only equality pairs.&#39;</span>

            <span class="n">equality_sets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_pair_candidates</span><span class="p">(</span><span class="n">equality_sets</span><span class="p">)</span>

            <span class="n">bias_word_embedding</span><span class="o">.</span><span class="n">_equalize</span><span class="p">(</span><span class="n">equality_sets</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">bias_word_embedding</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.evaluate_word_embedding"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.evaluate_word_embedding">[docs]</a>    <span class="k">def</span> <span class="nf">evaluate_word_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                <span class="n">kwargs_word_pairs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">kwargs_word_analogies</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate word pairs tasks and word analogies tasks.</span>

<span class="sd">        :param model: Word embedding.</span>
<span class="sd">        :param kwargs_word_pairs: Kwargs for</span>
<span class="sd">                                  evaluate_word_pairs</span>
<span class="sd">                                  method.</span>
<span class="sd">        :type kwargs_word_pairs: dict or None</span>
<span class="sd">        :param kwargs_word_analogies: Kwargs for</span>
<span class="sd">                                      evaluate_word_analogies</span>
<span class="sd">                                      method.</span>
<span class="sd">        :type evaluate_word_analogies: dict or None</span>
<span class="sd">        :return: Tuple of :class:`pandas.DataFrame`</span>
<span class="sd">                 for the evaluation results.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">evaluate_word_embedding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                                       <span class="n">kwargs_word_pairs</span><span class="p">,</span>
                                       <span class="n">kwargs_word_analogies</span><span class="p">)</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.learn_full_specific_words"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.learn_full_specific_words">[docs]</a>    <span class="k">def</span> <span class="nf">learn_full_specific_words</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed_specific_words</span><span class="p">,</span>
                                  <span class="n">max_non_specific_examples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Learn specific words given a list of seed specific wordsself.</span>

<span class="sd">        Using Linear SVM.</span>

<span class="sd">        :param list seed_specific_words: List of seed specific words</span>
<span class="sd">        :param int max_non_specific_examples: The number of non-specific words</span>
<span class="sd">                                              to sample for training</span>
<span class="sd">        :return: List of learned specific words and the classifier object</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">debug</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">debug</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">max_non_specific_examples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_non_specific_examples</span> <span class="o">=</span> <span class="n">MAX_NON_SPECIFIC_EXAMPLES</span>

        <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">non_specific_example_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
            <span class="n">is_specific</span> <span class="o">=</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">seed_specific_words</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_specific</span><span class="p">:</span>
                <span class="n">non_specific_example_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">non_specific_example_count</span> <span class="o">&lt;=</span> <span class="n">max_non_specific_examples</span><span class="p">:</span>
                    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">],</span> <span class="n">is_specific</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">],</span> <span class="n">is_specific</span><span class="p">))</span>

        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">RANDOM_STATE</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>

        <span class="n">clf</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span>
                        <span class="n">random_state</span><span class="o">=</span><span class="n">RANDOM_STATE</span><span class="p">)</span>

        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">full_specific_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
            <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span><span class="n">normalize</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">word</span><span class="p">])]</span>
            <span class="k">if</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
                <span class="n">full_specific_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">debug</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">full_specific_words</span><span class="p">,</span> <span class="n">clf</span>

        <span class="k">return</span> <span class="n">full_specific_words</span><span class="p">,</span> <span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span></div>

    <span class="k">def</span> <span class="nf">_plot_most_biased_one_cluster</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                      <span class="n">most_biased_neutral_words</span><span class="p">,</span> <span class="n">y_bias</span><span class="p">,</span>
                                      <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">most_biased_vectors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
                               <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">most_biased_neutral_words</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">plot_clustering_as_classification</span><span class="p">(</span><span class="n">most_biased_vectors</span><span class="p">,</span>
                                                 <span class="n">y_bias</span><span class="p">,</span>
                                                 <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                                                 <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<div class="viewcode-block" id="BiasWordEmbedding.compute_factual_association"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.compute_factual_association">[docs]</a>    <span class="k">def</span> <span class="nf">compute_factual_association</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">factual_properity</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute association of a factual property to the projection.</span>

<span class="sd">        Inspired by WEFAT (Word-Embedding Factual Association Test),</span>
<span class="sd">        but it is not the same:</span>
<span class="sd">        - Caliskan, A., Bryson, J. J., &amp; Narayanan, A. (2017).</span>
<span class="sd">        `Semantics derived automatically</span>
<span class="sd">        from language corpora contain human-like biases</span>
<span class="sd">        &lt;http://opus.bath.ac.uk/55288/&gt;`_.</span>
<span class="sd">        Science, 356(6334), 183-186.</span>

<span class="sd">        In a future version, the WEFAT will also be implemented.</span>

<span class="sd">        If a word doesn&#39;t exist in the word embedding,</span>
<span class="sd">        then it will be filtered out.</span>

<span class="sd">        For example, in :class:`responsibly.we.bias.GenderBiasWE`,</span>
<span class="sd">        the defuat factual property is the percentage of female</span>
<span class="sd">        in various occupations</span>
<span class="sd">        from the Labor Force Statistics of 2017 Population Survey,</span>
<span class="sd">        Taken from: https://arxiv.org/abs/1804.06876</span>

<span class="sd">        :param dict factual_properity: Dictionary of words</span>
<span class="sd">                                       and their factual values.</span>
<span class="sd">        :return: Pearson r, pvalue and the words with their</span>
<span class="sd">                 associated factual values</span>
<span class="sd">                 and their projection on the bias direction.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">points</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">project_on_direction</span><span class="p">(</span><span class="n">word</span><span class="p">))</span>
                  <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">factual_properity</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                  <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">}</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">points</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">points</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.plot_factual_association"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.plot_factual_association">[docs]</a>    <span class="k">def</span> <span class="nf">plot_factual_association</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">factual_properity</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Plot association of a factual property to the projection.</span>

<span class="sd">        See: :meth:`BiasWordEmbedding.compute_factual_association`</span>

<span class="sd">        :param dict factual_properity: Dictionary of words</span>
<span class="sd">                                       and their factual values.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_factual_association</span><span class="p">(</span><span class="n">factual_properity</span><span class="p">)</span>

        <span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">),</span> <span class="n">points</span> <span class="o">=</span> <span class="n">result</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">points</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Assocsion between Factual Property&#39;</span>
                  <span class="s1">&#39;and Projection on Direction &#39;</span>
                  <span class="s1">&#39;(Pearson R = </span><span class="si">{:0.2f}</span><span class="s1"> ; pvalue=</span><span class="si">{:0.2f}</span><span class="s1">)&#39;</span>
                  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">))</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Factual Property&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Projection on Direction&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ax</span></div>

<div class="viewcode-block" id="BiasWordEmbedding.plot_most_biased_clustering"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.BiasWordEmbedding.plot_most_biased_clustering">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">plot_most_biased_clustering</span><span class="p">(</span><span class="n">biased</span><span class="p">,</span> <span class="n">debiased</span><span class="p">,</span>
                                    <span class="n">seed</span><span class="o">=</span><span class="s1">&#39;ends&#39;</span><span class="p">,</span> <span class="n">n_extreme</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Plot clustering as classification of biased neutral words.</span>

<span class="sd">        :param biased: Biased word embedding of</span>
<span class="sd">                       :class:`~responsibly.we.bias.BiasWordEmbedding`.</span>
<span class="sd">        :param debiased: Debiased word embedding of</span>
<span class="sd">                         :class:`~responsibly.we.bias.BiasWordEmbedding`.</span>
<span class="sd">        :param seed: The definition of the seed vector.</span>
<span class="sd">                    Either by a tuple of two word ends,</span>
<span class="sd">                    or by `&#39;ends` for the pre-defined ends</span>
<span class="sd">                    or by `&#39;direction&#39;` for</span>
<span class="sd">                    the pre-defined direction vector.</span>
<span class="sd">        :param n_extrem: The number of extreme biased</span>
<span class="sd">                         neutral words to use.</span>
<span class="sd">        :return: Tuple of list of ax objects of the plot,</span>
<span class="sd">                 and a dictionary with the most positive</span>
<span class="sd">                 and negative words.</span>

<span class="sd">        Based on:</span>

<span class="sd">        - Gonen, H., &amp; Goldberg, Y. (2019).</span>
<span class="sd">          `Lipstick on a Pig:</span>
<span class="sd">          Debiasing Methods Cover up Systematic Gender Biases</span>
<span class="sd">          in Word Embeddings But do not Remove</span>
<span class="sd">          Them &lt;https://arxiv.org/abs/1903.03862&gt;`_.</span>
<span class="sd">          arXiv preprint arXiv:1903.03862.</span>

<span class="sd">        - https://github.com/gonenhila/gender_bias_lipstick</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># pylint: disable=protected-access,too-many-locals,line-too-long</span>

        <span class="k">assert</span> <span class="n">biased</span><span class="o">.</span><span class="n">positive_end</span> <span class="o">==</span> <span class="n">debiased</span><span class="o">.</span><span class="n">positive_end</span><span class="p">,</span> \
            <span class="s1">&#39;Postive ends should be the same.&#39;</span>
        <span class="k">assert</span> <span class="n">biased</span><span class="o">.</span><span class="n">negative_end</span> <span class="o">==</span> <span class="n">debiased</span><span class="o">.</span><span class="n">negative_end</span><span class="p">,</span> \
            <span class="s1">&#39;Negative ends should be the same.&#39;</span>

        <span class="n">seed_vector</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">get_seed_vector</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="n">biased</span><span class="p">)</span>

        <span class="n">neutral_words</span> <span class="o">=</span> <span class="n">biased</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;neutral_words&#39;</span><span class="p">]</span>
        <span class="n">neutral_word_vectors</span> <span class="o">=</span> <span class="p">(</span><span class="n">biased</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">neutral_words</span><span class="p">)</span>
        <span class="n">neutral_word_projections</span> <span class="o">=</span> <span class="p">[(</span><span class="n">normalize</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span> <span class="o">@</span> <span class="n">seed_vector</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">vector</span>
                                    <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">neutral_words</span><span class="p">,</span>
                                           <span class="n">neutral_word_vectors</span><span class="p">)]</span>

        <span class="n">neutral_word_projections</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">most_negative_words</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">neutral_word_projections</span><span class="p">[:</span><span class="n">n_extreme</span><span class="p">])</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">most_positive_words</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">neutral_word_projections</span><span class="p">[</span><span class="o">-</span><span class="n">n_extreme</span><span class="p">:])</span>

        <span class="n">most_biased_neutral_words</span> <span class="o">=</span> <span class="n">most_negative_words</span> <span class="o">+</span> <span class="n">most_positive_words</span>

        <span class="n">y_bias</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_extreme</span> <span class="o">+</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_extreme</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

        <span class="n">acc_biased</span> <span class="o">=</span> <span class="n">biased</span><span class="o">.</span><span class="n">_plot_most_biased_one_cluster</span><span class="p">(</span><span class="n">most_biased_neutral_words</span><span class="p">,</span>
                                                          <span class="n">y_bias</span><span class="p">,</span>
                                                          <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                                                          <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Biased - Accuracy=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_biased</span><span class="p">))</span>

        <span class="n">acc_debiased</span> <span class="o">=</span> <span class="n">debiased</span><span class="o">.</span><span class="n">_plot_most_biased_one_cluster</span><span class="p">(</span><span class="n">most_biased_neutral_words</span><span class="p">,</span>
                                                              <span class="n">y_bias</span><span class="p">,</span>
                                                              <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
                                                              <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Debiased - Accuracy=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc_debiased</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">axes</span><span class="p">,</span> <span class="p">{</span><span class="n">biased</span><span class="o">.</span><span class="n">positive_end</span><span class="p">:</span> <span class="n">most_positive_words</span><span class="p">,</span>
                      <span class="n">biased</span><span class="o">.</span><span class="n">negative_end</span><span class="p">:</span> <span class="n">most_negative_words</span><span class="p">}</span></div></div>


<div class="viewcode-block" id="GenderBiasWE"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE">[docs]</a><span class="k">class</span> <span class="nc">GenderBiasWE</span><span class="p">(</span><span class="n">BiasWordEmbedding</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Measure and adjust the Gender Bias in English Word Embedding.</span>

<span class="sd">    :param model: Word embedding model of ``gensim.model.KeyedVectors``</span>
<span class="sd">    :param bool only_lower: Whether the word embedding contrains</span>
<span class="sd">                            only lower case words</span>
<span class="sd">    :param bool verbose: Set verbosity</span>
<span class="sd">    :param str identify_direction: Set the method of identifying</span>
<span class="sd">                                   the gender direction:</span>
<span class="sd">                                   `&#39;single&#39;`, `&#39;sum&#39;` or `&#39;pca&#39;`.</span>
<span class="sd">    :param bool to_normalize: Whether to normalize all the vectors</span>
<span class="sd">                              (recommended!)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">only_lower</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">identify_direction</span><span class="o">=</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">to_normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                         <span class="n">only_lower</span><span class="o">=</span><span class="n">only_lower</span><span class="p">,</span>
                         <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
                         <span class="n">to_normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_data</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">identify_direction</span><span class="p">:</span>
            <span class="n">definitional</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">identify_direction</span> <span class="o">==</span> <span class="s1">&#39;single&#39;</span><span class="p">:</span>
                <span class="n">definitional</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;she&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">identify_direction</span> <span class="o">==</span> <span class="s1">&#39;sum&#39;</span><span class="p">:</span>
                <span class="n">definitional</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;definitional_pairs&#39;</span><span class="p">]))</span>
            <span class="k">elif</span> <span class="n">identify_direction</span> <span class="o">==</span> <span class="s1">&#39;pca&#39;</span><span class="p">:</span>
                <span class="n">definitional</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;definitional_pairs&#39;</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_identify_direction</span><span class="p">(</span><span class="s1">&#39;she&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">,</span>
                                     <span class="n">definitional</span><span class="p">,</span>
                                     <span class="n">identify_direction</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_initialize_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">BOLUKBASI_DATA</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">])</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">only_lower</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;specific_full_with_definitional_equalize&#39;</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">generate_words_forms</span><span class="p">(</span><span class="bp">self</span>
                                     <span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;specific_full_with_definitional_equalize&#39;</span><span class="p">])</span>  <span class="c1"># pylint: disable=C0301</span>

        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;word_group_keys&#39;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_filter_words_by_model</span><span class="p">(</span><span class="bp">self</span>
                                                           <span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;neutral_words&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_neutral_words</span><span class="p">(</span><span class="bp">self</span>
                                                                  <span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;specific_full_with_definitional_equalize&#39;</span><span class="p">])</span>  <span class="c1"># pylint: disable=C0301</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;neutral_words&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;word_group_keys&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;neutral_words&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="GenderBiasWE.plot_projection_scores"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.plot_projection_scores">[docs]</a>    <span class="k">def</span> <span class="nf">plot_projection_scores</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">words</span><span class="o">=</span><span class="s1">&#39;professions&#39;</span><span class="p">,</span> <span class="n">n_extreme</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                               <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis_projection_step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">words</span> <span class="o">==</span> <span class="s1">&#39;professions&#39;</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;profession_names&#39;</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">plot_projection_scores</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">n_extreme</span><span class="p">,</span>
                                              <span class="n">ax</span><span class="p">,</span> <span class="n">axis_projection_step</span><span class="p">)</span></div>

<div class="viewcode-block" id="GenderBiasWE.plot_dist_projections_on_direction"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.plot_dist_projections_on_direction">[docs]</a>    <span class="k">def</span> <span class="nf">plot_dist_projections_on_direction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word_groups</span><span class="o">=</span><span class="s1">&#39;bolukbasi&#39;</span><span class="p">,</span>
                                           <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word_groups</span> <span class="o">==</span> <span class="s1">&#39;bolukbasi&#39;</span><span class="p">:</span>
            <span class="n">word_groups</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
                           <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;word_group_keys&#39;</span><span class="p">]}</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">plot_dist_projections_on_direction</span><span class="p">(</span><span class="n">word_groups</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span></div>

<div class="viewcode-block" id="GenderBiasWE.plot_bias_across_word_embeddings"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.plot_bias_across_word_embeddings">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">plot_bias_across_word_embeddings</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">word_embedding_bias_dict</span><span class="p">,</span>
                                         <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scatter_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># pylint: disable=W0221</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">BOLUKBASI_DATA</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">][</span><span class="s1">&#39;neutral_profession_names&#39;</span><span class="p">]</span>
        <span class="c1"># TODO: is it correct for inheritance of class method?</span>
        <span class="nb">super</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">plot_bias_across_word_embeddings</span><span class="p">(</span><span class="n">word_embedding_bias_dict</span><span class="p">,</span>  <span class="c1"># pylint: disable=C0301</span>
                                                         <span class="n">words</span><span class="p">,</span>
                                                         <span class="n">ax</span><span class="p">,</span>
                                                         <span class="n">scatter_kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="GenderBiasWE.calc_direct_bias"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.calc_direct_bias">[docs]</a>    <span class="k">def</span> <span class="nf">calc_direct_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neutral_words</span><span class="o">=</span><span class="s1">&#39;professions&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">neutral_words</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">neutral_words</span> <span class="o">==</span> <span class="s1">&#39;professions&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">calc_direct_bias</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;neutral_profession_names&#39;</span><span class="p">],</span> <span class="n">c</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">calc_direct_bias</span><span class="p">(</span><span class="n">neutral_words</span><span class="p">)</span></div>

<div class="viewcode-block" id="GenderBiasWE.generate_closest_words_indirect_bias"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.generate_closest_words_indirect_bias">[docs]</a>    <span class="k">def</span> <span class="nf">generate_closest_words_indirect_bias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                             <span class="n">neutral_positive_end</span><span class="p">,</span>
                                             <span class="n">neutral_negative_end</span><span class="p">,</span>
                                             <span class="n">words</span><span class="o">=</span><span class="s1">&#39;professions&#39;</span><span class="p">,</span> <span class="n">n_extreme</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="c1"># pylint: disable=C0301</span>

        <span class="k">if</span> <span class="n">words</span> <span class="o">==</span> <span class="s1">&#39;professions&#39;</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;profession_names&#39;</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">generate_closest_words_indirect_bias</span><span class="p">(</span><span class="n">neutral_positive_end</span><span class="p">,</span>
                                                            <span class="n">neutral_negative_end</span><span class="p">,</span>
                                                            <span class="n">words</span><span class="p">,</span>
                                                            <span class="n">n_extreme</span><span class="o">=</span><span class="n">n_extreme</span><span class="p">)</span></div>

<div class="viewcode-block" id="GenderBiasWE.debias"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.debias">[docs]</a>    <span class="k">def</span> <span class="nf">debias</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;hard&#39;</span><span class="p">,</span> <span class="n">neutral_words</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">equality_sets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="c1"># pylint: disable=line-too-long</span>
        <span class="k">if</span> <span class="n">method</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;hard&#39;</span><span class="p">,</span> <span class="s1">&#39;neutralize&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">neutral_words</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">neutral_words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;neutral_words&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;hard&#39;</span> <span class="ow">and</span> <span class="n">equality_sets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">equality_sets</span> <span class="o">=</span> <span class="p">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;equalize_pairs&#39;</span><span class="p">]}</span>
            <span class="n">equality_sets</span> <span class="o">|=</span> <span class="p">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;definitional_pairs&#39;</span><span class="p">]}</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">debias</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">neutral_words</span><span class="p">,</span> <span class="n">equality_sets</span><span class="p">,</span>
                              <span class="n">inplace</span><span class="p">)</span></div>

<div class="viewcode-block" id="GenderBiasWE.learn_full_specific_words"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.learn_full_specific_words">[docs]</a>    <span class="k">def</span> <span class="nf">learn_full_specific_words</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed_specific_words</span><span class="o">=</span><span class="s1">&#39;bolukbasi&#39;</span><span class="p">,</span>
                                  <span class="n">max_non_specific_examples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                  <span class="n">debug</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">seed_specific_words</span> <span class="o">==</span> <span class="s1">&#39;bolukbasi&#39;</span><span class="p">:</span>
            <span class="n">seed_specific_words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="s1">&#39;specific_seed&#39;</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">learn_full_specific_words</span><span class="p">(</span><span class="n">seed_specific_words</span><span class="p">,</span>
                                                 <span class="n">max_non_specific_examples</span><span class="p">,</span>
                                                 <span class="n">debug</span><span class="p">)</span></div>

<div class="viewcode-block" id="GenderBiasWE.compute_factual_association"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.compute_factual_association">[docs]</a>    <span class="k">def</span> <span class="nf">compute_factual_association</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                    <span class="n">factual_properity</span><span class="o">=</span><span class="n">OCCUPATION_FEMALE_PRECENTAGE</span><span class="p">):</span>  <span class="c1"># pylint: disable=line-too-long</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">compute_factual_association</span><span class="p">(</span><span class="n">factual_properity</span><span class="p">)</span></div>

<div class="viewcode-block" id="GenderBiasWE.plot_factual_association"><a class="viewcode-back" href="../../../word-embedding-bias.html#responsibly.we.bias.GenderBiasWE.plot_factual_association">[docs]</a>    <span class="k">def</span> <span class="nf">plot_factual_association</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                 <span class="n">factual_properity</span><span class="o">=</span><span class="n">OCCUPATION_FEMALE_PRECENTAGE</span><span class="p">,</span>  <span class="c1"># pylint: disable=line-too-long</span>
                                 <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">plot_factual_association</span><span class="p">(</span><span class="n">factual_properity</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span></div></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">Responsibly</a></h1>






<p>
<iframe src="https://ghbtns.com/github-btn.html?user=ResponsiblyAI&repo=responsibly&type=star&v=2&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../dataset.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fairness.html">Classification Fairness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../word-embedding-bias.html">Word Embedding Bias</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../demos.html">Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about/contributing.html">For Contributors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about/changelog.html">Revision History</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../about/license.html">License</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Shlomi Hod.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    
    <a href="https://github.com/ResponsiblyAI/responsibly" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>